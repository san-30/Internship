{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a36659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a3a03b",
   "metadata": {},
   "source": [
    "## Q1 Scrape the details of most viewed videos on YouTube from Wikipedia. Url \n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: \n",
    "A) Rank \n",
    "B) Name \n",
    "C) Artist \n",
    "D) Upload date \n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17f2a634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1.', '\"Baby Shark Dance\"', \"Pinkfong Baby Shark - Kids' Songs & Stories\", '13.48', 'June 17, 2016'], ['2.', '\"Despacito\"', 'Luis Fonsi', '8.28', 'January 12, 2017'], ['3.', '\"Johny Johny Yes Papa\"', \"LooLoo Kids - Nursery Rhymes and Children's Songs\", '6.82', 'October 8, 2016'], ['4.', '\"Bath Song\"', 'Cocomelon - Nursery Rhymes', '6.45', 'May 2, 2018'], ['5.', '\"Shape of You\"', 'Ed Sheeran', '6.11', 'January 30, 2017'], ['6.', '\"See You Again\"', 'Wiz Khalifa', '6.05', 'April 6, 2015'], ['7.', '\"Wheels on the Bus\"', 'Cocomelon - Nursery Rhymes', '5.62', 'May 24, 2018'], ['8.', '\"Phonics Song with Two Words\"', 'ChuChu TV Nursery Rhymes & Kids Songs', '5.52', 'March 6, 2014'], ['9.', '\"Uptown Funk\"', 'Mark Ronson', '5.05', 'November 19, 2014'], ['10.', '\"Learning Colors – Colorful Eggs on a Farm\"', 'Miroshka TV', '4.99', 'February 27, 2018'], ['11.', '\"Gangnam Style\"', 'officialpsy', '4.92', 'July 15, 2012'], ['12.', '\"Masha and the Bear – Recipe for Disaster\"', 'Get Movies', '4.56', 'January 31, 2012'], ['13.', '\"Dame Tu Cosita\"', 'Ultra Records', '4.46', 'April 5, 2018'], ['14.', '\"Axel F\"', 'Crazy Frog', '4.09', 'June 16, 2009'], ['15.', '\"Sugar\"', 'Maroon 5', '3.95', 'January 14, 2015'], ['16.', '\"Counting Stars\"', 'OneRepublic', '3.89', 'May 31, 2013'], ['17.', '\"Roar\"', 'Katy Perry', '3.89', 'September 5, 2013'], ['18.', '\"Baa Baa Black Sheep\"', 'Cocomelon - Nursery Rhymes', '3.80', 'June 25, 2018'], ['19.', '\"Waka Waka (This Time for Africa)\"', 'Shakira', '3.75', 'June 4, 2010'], ['20.', '\"Sorry\"', 'Justin Bieber', '3.72', 'October 22, 2015'], ['21.', '\"Lakdi Ki Kathi\"', 'Jingle Toons', '3.71', 'June 14, 2018'], ['22.', '\"Thinking Out Loud\"', 'Ed Sheeran', '3.67', 'October 7, 2014'], ['23.', '\"Dark Horse\"', 'Katy Perry', '3.60', 'February 20, 2014'], ['24.', '\"Humpty the train on a fruits ride\"', 'Kiddiestv Hindi - Nursery Rhymes & Kids Songs', '3.58', 'January 26, 2018'], ['25.', '\"Perfect\"', 'Ed Sheeran', '3.56', 'November 9, 2017'], ['26.', '\"Let Her Go\"', 'Passenger', '3.53', 'July 25, 2012'], ['27.', '\"Faded\"', 'Alan Walker', '3.53', 'December 3, 2015'], ['28.', '\"Girls Like You\"', 'Maroon 5', '3.50', 'May 31, 2018'], ['29.', '\"Shree Hanuman Chalisa\"', 'T-Series Bhakti Sagar', '3.48', 'May 10, 2011'], ['30.', '\"Lean On\"', 'Major Lazer Official', '3.48', 'March 22, 2015']]\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    driver = webdriver.Edge()\n",
    "    driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "\n",
    "    # To scarpe data (i.e. Rank, Name, Artist, Upload Date, Views) \n",
    "    # 1. Name\n",
    "\n",
    "    tbody = driver.find_element(By.XPATH, '/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]')\n",
    "    time.sleep(2)\n",
    "\n",
    "    data1 = []\n",
    "    for tr in tbody.find_elements(By.XPATH, \"//tr\")[1:]:\n",
    "        r = [td.text.replace(\"\\n\", ' ') for td in tr.find_elements(By.XPATH, './/td')]\n",
    "        if(len(r) == 6):\n",
    "            rank = r[0]\n",
    "            out = re.sub(r\" ?\\[[^)]+\\]\", \"\", r[1])\n",
    "            name = out\n",
    "            artist = r[2]\n",
    "            views = r[3]\n",
    "            upload_date = r[4]\n",
    "            data1.append([rank, name, artist, views, upload_date])\n",
    "\n",
    "    print(data1)\n",
    "    print(len(data1))\n",
    "    \n",
    "\n",
    "except NoSuchElementException as e:\n",
    "    print(\"Exception Raised \", e)\n",
    "    print(\"Refreshing the Page \")\n",
    "    time.sleep(3)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ffc95e",
   "metadata": {},
   "source": [
    "## Q1 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ea0f5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                                         Name  \\\n",
      "0    1.                           \"Baby Shark Dance\"   \n",
      "1    2.                                  \"Despacito\"   \n",
      "2    3.                       \"Johny Johny Yes Papa\"   \n",
      "3    4.                                  \"Bath Song\"   \n",
      "4    5.                               \"Shape of You\"   \n",
      "5    6.                              \"See You Again\"   \n",
      "6    7.                          \"Wheels on the Bus\"   \n",
      "7    8.                \"Phonics Song with Two Words\"   \n",
      "8    9.                                \"Uptown Funk\"   \n",
      "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"   \n",
      "10  11.                              \"Gangnam Style\"   \n",
      "11  12.   \"Masha and the Bear – Recipe for Disaster\"   \n",
      "12  13.                             \"Dame Tu Cosita\"   \n",
      "13  14.                                     \"Axel F\"   \n",
      "14  15.                                      \"Sugar\"   \n",
      "15  16.                             \"Counting Stars\"   \n",
      "16  17.                                       \"Roar\"   \n",
      "17  18.                        \"Baa Baa Black Sheep\"   \n",
      "18  19.           \"Waka Waka (This Time for Africa)\"   \n",
      "19  20.                                      \"Sorry\"   \n",
      "20  21.                             \"Lakdi Ki Kathi\"   \n",
      "21  22.                          \"Thinking Out Loud\"   \n",
      "22  23.                                 \"Dark Horse\"   \n",
      "23  24.          \"Humpty the train on a fruits ride\"   \n",
      "24  25.                                    \"Perfect\"   \n",
      "25  26.                                 \"Let Her Go\"   \n",
      "26  27.                                      \"Faded\"   \n",
      "27  28.                             \"Girls Like You\"   \n",
      "28  29.                      \"Shree Hanuman Chalisa\"   \n",
      "29  30.                                    \"Lean On\"   \n",
      "\n",
      "                                               Artist  Views  \\\n",
      "0         Pinkfong Baby Shark - Kids' Songs & Stories  13.48   \n",
      "1                                          Luis Fonsi   8.28   \n",
      "2   LooLoo Kids - Nursery Rhymes and Children's Songs   6.82   \n",
      "3                          Cocomelon - Nursery Rhymes   6.45   \n",
      "4                                          Ed Sheeran   6.11   \n",
      "5                                         Wiz Khalifa   6.05   \n",
      "6                          Cocomelon - Nursery Rhymes   5.62   \n",
      "7               ChuChu TV Nursery Rhymes & Kids Songs   5.52   \n",
      "8                                         Mark Ronson   5.05   \n",
      "9                                         Miroshka TV   4.99   \n",
      "10                                        officialpsy   4.92   \n",
      "11                                         Get Movies   4.56   \n",
      "12                                      Ultra Records   4.46   \n",
      "13                                         Crazy Frog   4.09   \n",
      "14                                           Maroon 5   3.95   \n",
      "15                                        OneRepublic   3.89   \n",
      "16                                         Katy Perry   3.89   \n",
      "17                         Cocomelon - Nursery Rhymes   3.80   \n",
      "18                                            Shakira   3.75   \n",
      "19                                      Justin Bieber   3.72   \n",
      "20                                       Jingle Toons   3.71   \n",
      "21                                         Ed Sheeran   3.67   \n",
      "22                                         Katy Perry   3.60   \n",
      "23      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   3.58   \n",
      "24                                         Ed Sheeran   3.56   \n",
      "25                                          Passenger   3.53   \n",
      "26                                        Alan Walker   3.53   \n",
      "27                                           Maroon 5   3.50   \n",
      "28                              T-Series Bhakti Sagar   3.48   \n",
      "29                               Major Lazer Official   3.48   \n",
      "\n",
      "          Upload Date  \n",
      "0       June 17, 2016  \n",
      "1    January 12, 2017  \n",
      "2     October 8, 2016  \n",
      "3         May 2, 2018  \n",
      "4    January 30, 2017  \n",
      "5       April 6, 2015  \n",
      "6        May 24, 2018  \n",
      "7       March 6, 2014  \n",
      "8   November 19, 2014  \n",
      "9   February 27, 2018  \n",
      "10      July 15, 2012  \n",
      "11   January 31, 2012  \n",
      "12      April 5, 2018  \n",
      "13      June 16, 2009  \n",
      "14   January 14, 2015  \n",
      "15       May 31, 2013  \n",
      "16  September 5, 2013  \n",
      "17      June 25, 2018  \n",
      "18       June 4, 2010  \n",
      "19   October 22, 2015  \n",
      "20      June 14, 2018  \n",
      "21    October 7, 2014  \n",
      "22  February 20, 2014  \n",
      "23   January 26, 2018  \n",
      "24   November 9, 2017  \n",
      "25      July 25, 2012  \n",
      "26   December 3, 2015  \n",
      "27       May 31, 2018  \n",
      "28       May 10, 2011  \n",
      "29     March 22, 2015  \n"
     ]
    }
   ],
   "source": [
    "#Create a DataFrame\n",
    "df = pd.DataFrame(data1, columns=['Rank', 'Name', 'Artist', 'Views', 'Upload Date'])\n",
    "\n",
    "#Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82ebab1",
   "metadata": {},
   "source": [
    "## Q2 Scrape the details team India’s international fixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/. \n",
    "You need to find following details: \n",
    "A) Series \n",
    "B) Place \n",
    "C) Date \n",
    "D) Time \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "810b8d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    driver = webdriver.Edge()\n",
    "    driver.get('https://www.bcci.tv/')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    button_close = driver.find_element(By.XPATH, \"/html/body/div[4]/div/div/button\")  \n",
    "    button_close.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    button_fixtures = driver.find_element(By.XPATH, \"/html/body/header/div[3]/div[1]/ul/div[1]/a[2]\")  \n",
    "    button_fixtures.click()\n",
    "    \n",
    "    #scroll\n",
    "    \n",
    "    for _ in range(10):\n",
    "        driver.execute_script(\"window.scrollBy(0,1000)\")\n",
    "        time.sleep(2)\n",
    "\n",
    "except NoSuchElementException as e:\n",
    "    print(\"Exception Raised \", e)\n",
    "    print(\"Refreshing the Page \")\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "61192e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Series\n",
    "    \n",
    "series = []\n",
    "series_elements = driver.find_elements(By.XPATH,\"//h5[@class='match-tournament-name ng-binding']\")\n",
    "time.sleep(2)\n",
    "for i in series_elements:\n",
    "    series.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "467dc5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ICC MENS WORLD CUP 2023', 'ICC MENS WORLD CUP 2023', 'ICC MENS WORLD CUP 2023', 'ICC MENS WORLD CUP 2023', 'ICC MENS WORLD CUP 2023', 'ICC MENS WORLD CUP 2023', 'ICC MENS WORLD CUP 2023', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'AUSTRALIA TOUR OF INDIA 2023-24', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'AUSTRALIA TOUR OF INDIA 2023-24', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'AUSTRALIA TOUR OF INDIA 2023-24', 'AUSTRALIA TOUR OF INDIA 2023-24', 'AUSTRALIA TOUR OF INDIA 2023-24', 'INDIA TOUR OF SOUTH AFRICA 2023-24', 'INDIA TOUR OF SOUTH AFRICA 2023-24', 'INDIA TOUR OF SOUTH AFRICA 2023-24', 'INDIA TOUR OF SOUTH AFRICA 2023-24', 'INDIA TOUR OF SOUTH AFRICA 2023-24', 'INDIA TOUR OF SOUTH AFRICA 2023-24', 'INDIA TOUR OF SOUTH AFRICA 2023-24', 'INDIA TOUR OF SOUTH AFRICA 2023-24', 'AFGHANISTAN TOUR OF INDIA 2023-24', 'AFGHANISTAN TOUR OF INDIA 2023-24', 'AFGHANISTAN TOUR OF INDIA 2023-24', 'ENGLAND TOUR OF INDIA 2023-24', 'ENGLAND TOUR OF INDIA 2023-24', 'ENGLAND TOUR OF INDIA 2023-24', 'ENGLAND TOUR OF INDIA 2023-24', 'ENGLAND TOUR OF INDIA 2023-24', 'ICC MENS WORLD CUP 2023', 'ICC MENS WORLD CUP 2023', '19TH ASIAN GAMES HANGZHOU 2022', '19TH ASIAN GAMES HANGZHOU 2022', 'ICC MENS WORLD CUP 2023 WARM-UP MATCHES', '19TH ASIAN GAMES HANGZHOU 2022', 'ICC MENS WORLD CUP 2023 WARM-UP MATCHES', 'AUSTRALIA TOUR OF INDIA 2023-24', '19TH ASIAN GAMES HANGZHOU 2022', 'AUSTRALIA TOUR OF INDIA 2023-24', '19TH ASIAN GAMES HANGZHOU 2022', 'AUSTRALIA TOUR OF INDIA 2023-24', '19TH ASIAN GAMES HANGZHOU 2022', 'ASIA CUP 2023', 'ASIA CUP 2023', 'ASIA CUP 2023', 'ASIA CUP 2023', 'ASIA CUP 2023', 'ASIA CUP 2023', 'INDIA TOUR OF IRELAND 2023', 'INDIA TOUR OF IRELAND 2023', 'INDIA TOUR OF IRELAND 2023', 'INDIA TOUR OF WEST INDIES 2023', 'INDIA TOUR OF WEST INDIES 2023', 'INDIA TOUR OF WEST INDIES 2023', 'INDIA TOUR OF WEST INDIES 2023', 'INDIA TOUR OF WEST INDIES 2023', 'INDIA TOUR OF WEST INDIES 2023', 'INDIA TOUR OF WEST INDIES 2023', 'INDIA TOUR OF WEST INDIES 2023', 'ACC MENS EMERGING TEAMS ASIA CUP', 'INDIA WOMEN TOUR OF BANGLADESH 2023', 'ACC MENS EMERGING TEAMS ASIA CUP', 'ACC MENS EMERGING TEAMS ASIA CUP', 'INDIA TOUR OF WEST INDIES 2023', 'ACC MENS EMERGING TEAMS ASIA CUP', 'ACC MENS EMERGING TEAMS ASIA CUP', 'INDIA WOMEN TOUR OF BANGLADESH 2023', 'ACC MENS EMERGING TEAMS ASIA CUP', 'ACC MENS EMERGING TEAMS ASIA CUP', 'ACC MENS EMERGING TEAMS ASIA CUP', 'ACC MENS EMERGING TEAMS ASIA CUP', 'INDIA WOMEN TOUR OF BANGLADESH 2023', 'ACC MENS EMERGING TEAMS ASIA CUP', 'ACC MENS EMERGING TEAMS ASIA CUP', 'ACC MENS EMERGING TEAMS ASIA CUP', 'ACC MENS EMERGING TEAMS ASIA CUP', 'INDIA WOMEN TOUR OF BANGLADESH 2023', 'ACC MENS EMERGING TEAMS ASIA CUP', 'ACC MENS EMERGING TEAMS ASIA CUP', 'INDIA TOUR OF WEST INDIES 2023', 'INDIA WOMEN TOUR OF BANGLADESH 2023', 'INDIA WOMEN TOUR OF BANGLADESH 2023', 'WOMENS EMERGING TEAMS ASIA CUP 2023', 'WOMENS EMERGING TEAMS ASIA CUP 2023', 'WOMENS EMERGING TEAMS ASIA CUP 2023', 'WOMENS EMERGING TEAMS ASIA CUP 2023', 'WOMENS EMERGING TEAMS ASIA CUP 2023', 'WOMENS EMERGING TEAMS ASIA CUP 2023', 'ICC WORLD TEST CHAMPIONSHIP FINAL 2023', 'AUSTRALIA TOUR OF INDIA 2023', 'AUSTRALIA TOUR OF INDIA 2023', 'AUSTRALIA TOUR OF INDIA 2023', 'AUSTRALIA TOUR OF INDIA 2023', 'AUSTRALIA TOUR OF INDIA 2023', 'ICC WOMENS T20 WORLD CUP 2023', 'ICC WOMENS T20 WORLD CUP 2023', 'ICC WOMENS T20 WORLD CUP 2023', 'AUSTRALIA TOUR OF INDIA 2023', 'ICC WOMENS T20 WORLD CUP 2023', 'ICC WOMENS T20 WORLD CUP 2023', 'AUSTRALIA TOUR OF INDIA 2023', 'WOMENS T20I TRI-SERIES IN SOUTH AFRICA 2023', 'NEW ZEALAND TOUR OF INDIA 2022-23', 'WOMENS T20I TRI-SERIES IN SOUTH AFRICA 2023', 'NEW ZEALAND TOUR OF INDIA 2022-23', 'ICC WOMENS U19 T20 WORLD CUP 2023', 'WOMENS T20I TRI-SERIES IN SOUTH AFRICA 2023', 'NEW ZEALAND TOUR OF INDIA 2022-23', 'ICC WOMENS U19 T20 WORLD CUP 2023', 'NEW ZEALAND TOUR OF INDIA 2022-23', 'WOMENS T20I TRI-SERIES IN SOUTH AFRICA 2023', 'ICC WOMENS U19 T20 WORLD CUP 2023', 'ICC WOMENS U19 T20 WORLD CUP 2023', 'NEW ZEALAND TOUR OF INDIA 2022-23', 'WOMENS T20I TRI-SERIES IN SOUTH AFRICA 2023', 'ICC WOMENS U19 T20 WORLD CUP 2023', 'NEW ZEALAND TOUR OF INDIA 2022-23', 'ICC WOMENS U19 T20 WORLD CUP 2023', 'SRI LANKA TOUR OF INDIA 2022-23', 'ICC WOMENS U19 T20 WORLD CUP 2023', 'SRI LANKA TOUR OF INDIA 2022-23', 'SRI LANKA TOUR OF INDIA 2022-23', 'SRI LANKA TOUR OF INDIA 2022-23', 'SRI LANKA TOUR OF INDIA 2022-23', 'INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19', 'SRI LANKA TOUR OF INDIA 2022-23', 'INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19', 'INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19', 'INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19', 'INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19', 'INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19', 'INDIA TOUR OF BANGLADESH 2022-23', 'AUSTRALIA WOMEN TOUR OF INDIA 2022', 'AUSTRALIA WOMEN TOUR OF INDIA 2022', 'AUSTRALIA WOMEN TOUR OF INDIA 2022', 'INDIA TOUR OF BANGLADESH 2022-23', 'AUSTRALIA WOMEN TOUR OF INDIA 2022', 'INDIA TOUR OF BANGLADESH 2022-23', 'AUSTRALIA WOMEN TOUR OF INDIA 2022', 'INDIA TOUR OF BANGLADESH 2022-23', 'NEW ZEALAND WM U19 IN INDIA T20 SERIES', 'INDIA A IN BANGLADESH MULTI DAY SERIES', 'NEW ZEALAND WM U19 IN INDIA T20 SERIES', 'INDIA TOUR OF BANGLADESH 2022-23', 'NEW ZEALAND WM U19 IN INDIA T20 SERIES', 'INDIA TOUR OF NEW ZEALAND 2022-23', 'NEW ZEALAND WM U19 IN INDIA T20 SERIES', 'INDIA A IN BANGLADESH MULTI DAY SERIES', 'NEW ZEALAND WM U19 IN INDIA T20 SERIES', 'INDIA TOUR OF NEW ZEALAND 2022-23', 'INDIA TOUR OF NEW ZEALAND 2022-23', 'WEST INDIES WM U19 VS NEW ZEALAND WM U19 IN INDIA', 'WEST INDIES WM U19 VS NEW ZEALAND WM U19 IN INDIA', 'INDIA TOUR OF NEW ZEALAND 2022-23', 'INDIA TOUR OF NEW ZEALAND 2022-23', 'INDIA TOUR OF NEW ZEALAND 2022-23', 'ICC MENS T20 WORLD CUP 2022', 'ICC MENS T20 WORLD CUP 2022', 'ICC MENS T20 WORLD CUP 2022', 'ICC MENS T20 WORLD CUP 2022', 'ICC MENS T20 WORLD CUP 2022', 'ICC MENS T20 WORLD CUP 2022', 'ICC T20 WORLD CUP WARM-UP MATCHES 2022', 'ICC T20 WORLD CUP WARM-UP MATCHES 2022', 'ASIA CUP WOMENS 2022', 'ASIA CUP WOMENS 2022', 'SOUTH AFRICA TOUR OF INDIA 2022', 'ASIA CUP WOMENS 2022', 'SOUTH AFRICA TOUR OF INDIA 2022', 'ASIA CUP WOMENS 2022', 'ASIA CUP WOMENS 2022', 'SOUTH AFRICA TOUR OF INDIA 2022', 'SOUTH AFRICA TOUR OF INDIA 2022', 'ASIA CUP WOMENS 2022', 'ASIA CUP WOMENS 2022', 'SOUTH AFRICA TOUR OF INDIA 2022', 'ASIA CUP WOMENS 2022', 'SOUTH AFRICA TOUR OF INDIA 2022', 'NEW ZEALAND A TOUR OF INDIA', 'AUSTRALIA TOUR OF INDIA 2022', 'NEW ZEALAND A TOUR OF INDIA', 'INDIA WOMEN TOUR OF ENGLAND 2022', 'AUSTRALIA TOUR OF INDIA 2022', 'NEW ZEALAND A TOUR OF INDIA', 'INDIA WOMEN TOUR OF ENGLAND 2022', 'AUSTRALIA TOUR OF INDIA 2022', 'INDIA WOMEN TOUR OF ENGLAND 2022', 'INDIA WOMEN TOUR OF ENGLAND 2022', 'NEW ZEALAND A TOUR OF INDIA', 'INDIA WOMEN TOUR OF ENGLAND 2022', 'INDIA WOMEN TOUR OF ENGLAND 2022', 'ASIA CUP 2022', 'NEW ZEALAND A TOUR OF INDIA', 'ASIA CUP 2022', 'ASIA CUP 2022', 'NEW ZEALAND A TOUR OF INDIA', 'ASIA CUP 2022', 'ASIA CUP 2022']\n",
      "211\n"
     ]
    }
   ],
   "source": [
    "print(series)\n",
    "print(len(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e820363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Place\n",
    "    \n",
    "place = []\n",
    "place_elements = driver.find_elements(By.XPATH,\"//div[@class='match-place ng-scope']\")\n",
    "time.sleep(2)\n",
    "for i in place_elements:\n",
    "    place.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e3b4da7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Narendra Modi Stadium, Ahmedabad', 'Maharashtra Cricket Association Stadium, Pune', 'Himachal Pradesh Cricket Association Stadium, Dharamsala', 'Bharat Ratna Shri Atal Bihari Vajpayee Ekana Cricket Stadium, Lucknow', 'Wankhede Stadium, Mumbai', 'Eden Gardens, Kolkata', 'M Chinnaswamy Stadium, Bengaluru', 'DVR Ground,Mulapadu, Vijayawada', 'CP Ground,Mulapadu, Vijayawada', 'DVR Ground,Mulapadu, Vijayawada', 'CP Ground,Mulapadu, Vijayawada', 'DVR Ground,Mulapadu, Vijayawada', 'CP Ground,Mulapadu, Vijayawada', 'DVR Ground,Mulapadu, Vijayawada', 'CP Ground,Mulapadu, Vijayawada', 'DVR Ground,Mulapadu, Vijayawada', 'CP Ground,Mulapadu, Vijayawada', 'Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium, Visakhapatnam', 'DVR Ground,Mulapadu, Vijayawada', 'CP Ground,Mulapadu, Vijayawada', 'Greenfield International Stadium, Thiruvananthapuram', 'CP Ground,Mulapadu, Vijayawada', 'DVR Ground,Mulapadu, Vijayawada', 'Barsapara Cricket Stadium, Guwahati', 'Vidarbha Cricket Association Stadium, Nagpur', 'Rajiv Gandhi International Stadium, Hyderabad', 'Kingsmead, Durban', \"St George's Park, Gqeberha\", 'The Wanderers Stadium, Johannesburg', 'Johannesburg', \"St George's Park, Gqeberha\", 'Boland Park, Paarl', 'SuperSport Park, Centurion', 'Newlands, Cape Town', 'Punjab Cricket Association IS Bindra Stadium, Mohali', 'Holkar Cricket Stadium, Indore', 'M Chinnaswamy Stadium, Bengaluru', 'Rajiv Gandhi International Stadium, Hyderabad', 'Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium, Visakhapatnam', 'Saurashtra Cricket Association Stadium, Rajkot', 'JSCA International Stadium Complex, Ranchi', 'Himachal Pradesh Cricket Association Stadium, Dharamsala', 'Arun Jaitley Stadium, Delhi', 'MA Chidambaram Stadium, Chennai', 'Pingfeng Cricket Field, Hangzhou', 'Pingfeng Cricket Field, Hangzhou', 'Greenfield International Stadium, Thiruvananthapuram', 'Pingfeng Cricket Field, Hangzhou', 'Barsapara Cricket Stadium, Guwahati', 'Saurashtra Cricket Association Stadium, Rajkot', 'Pingfeng Cricket Field, Hangzhou', 'Holkar Cricket Stadium, Indore', 'Pingfeng Cricket Field, Hangzhou', 'Punjab Cricket Association IS Bindra Stadium, Mohali', 'Pingfeng Cricket Field, Hangzhou', 'R Premadasa International Stadium, Colombo', 'R Premadasa International Stadium, Colombo', 'R Premadasa International Stadium, Colombo', 'R Premadasa International Stadium, Colombo', 'Pallekele International Cricket Stadium, Pallekele', 'Pallekele International Cricket Stadium, Pallekele', 'The Village, Dublin', 'The Village, Dublin', 'The Village, Dublin', 'Central Broward Regional Park Stadium Turf Ground, Florida', 'Central Broward Regional Park Stadium Turf Ground, Florida', 'National Stadium, Guyana', 'National Stadium, Guyana', 'Brian Lara Stadium, Trinidad', 'Brian Lara Stadium, Trinidad', 'Kensington Oval, Barbados', 'Kensington Oval, Barbados', 'R.Premadasa Stadium, Colombo', 'Shere Bangla National Stadium, Mirpur, Dhaka', 'R.Premadasa Stadium, Colombo', 'P Sara Oval, Colombo', \"Queen's Park Oval, Trinidad\", 'R.Premadasa Stadium, Colombo', 'P Sara Oval, Colombo', 'Shere Bangla National Stadium, Mirpur, Dhaka', 'R.Premadasa Stadium, Colombo', 'P Sara Oval, Colombo', 'R.Premadasa Stadium, Colombo', 'P Sara Oval, Colombo', 'Shere Bangla National Stadium, Mirpur, Dhaka', 'Colombo Cricket Club Ground, Colombo', 'Singhalese Sports Club, Colombo', 'Singhalese Sports Club, Colombo', 'Colombo Cricket Club Ground, Colombo', 'Shere Bangla National Stadium, Mirpur, Dhaka', 'Singhalese Sports Club, Colombo', 'Colombo Cricket Club Ground, Colombo', 'Windsor Park, Dominica', 'Shere Bangla National Stadium, Mirpur, Dhaka', 'Shere Bangla National Stadium, Mirpur, Dhaka', 'Tin Kwong Road Recreation Ground, Hong Kong', 'Tin Kwong Road Recreation Ground, Hong Kong', 'Tin Kwong Road Recreation Ground, Hong Kong', 'Tin Kwong Road Recreation Ground, Hong Kong', 'Tin Kwong Road Recreation Ground, Hong Kong', 'Tin Kwong Road Recreation Ground, Hong Kong', 'Kennington Oval, London', 'MA Chidambaram Stadium, Chennai', 'Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium, Visakhapatnam', 'Wankhede Stadium, Mumbai', 'Narendra Modi Stadium, Ahmedabad', 'Holkar Cricket Stadium, Indore', 'Newlands, Cape Town', \"St George's Park, Gqeberha\", \"St George's Park, Gqeberha\", 'Arun Jaitley Stadium, Delhi', 'Newlands, Cape Town', 'Newlands, Cape Town', 'Vidarbha Cricket Association Stadium, Nagpur', 'Buffalo Park, East London', 'Narendra Modi Stadium, Ahmedabad', 'Buffalo Park, East London', 'Bharat Ratna Shri Atal Bihari Vajpayee Ekana Cricket Stadium, Lucknow', 'JB Marks Oval, Potchefstroom', 'Buffalo Park, East London', 'JSCA International Stadium Complex, Ranchi', 'JB Marks Oval, Potchefstroom', 'Holkar Cricket Stadium, Indore', 'Buffalo Park, East London', 'JB Marks Oval, Potchefstroom', 'North-West University Oval, Potchefstroom', 'Shaheed Veer Narayan Singh International Cricket Stadium, Raipur', 'Buffalo Park, East London', 'Willowmoore Park B Field, Benoni', 'Rajiv Gandhi International Stadium, Hyderabad', 'Willowmoore Park, Benoni', 'Greenfield International Stadium, Thiruvananthapuram', 'Willowmoore Park B Field, Benoni', 'Eden Gardens, Kolkata', 'Barsapara Cricket Stadium, Guwahati', 'Saurashtra Cricket Association Stadium, Rajkot', 'Maharashtra Cricket Association Stadium, Pune', 'Steyn City School Ground, Pretoria', 'Wankhede Stadium, Mumbai', 'Steyn City School Ground, Pretoria', 'Steyn City School Ground, Pretoria', 'Steyn City School Ground, Pretoria', 'Steyn City School Ground, Pretoria', 'Steyn City School Ground, Pretoria', 'Shere Bangla National Stadium, Mirpur, Dhaka', 'Brabourne - CCI, Mumbai', 'Brabourne - CCI, Mumbai', 'Brabourne - CCI, Mumbai', 'Zahur Ahmed Chowdhury Stadium, Chattogram', 'DY Patil Stadium, NAVI MUMBAI', 'Zahur Ahmed Chowdhury Stadium, Chattogram', 'DY Patil Stadium, NAVI MUMBAI', 'Shere Bangla National Stadium, Mirpur, Dhaka', 'Sharad Pawar Cricket Academy BKC, Mumbai', 'Sylhet International Cricket Stadium, Sylhet', 'Sharad Pawar Cricket Academy BKC, Mumbai', 'Shere Bangla National Stadium, Mirpur, Dhaka', 'Sharad Pawar Cricket Academy BKC, Mumbai', 'Hagley Oval, Christchurch', 'Sharad Pawar Cricket Academy BKC, Mumbai', 'Sheikh Kamal International Cricket Stadium, Cox Bazar', 'Sharad Pawar Cricket Academy BKC, Mumbai', 'Seddon Park, Hamilton', 'Eden Park, Auckland', 'Dr DY Patil Sports Academy, Mumbai', 'Dr DY Patil Sports Academy, Mumbai', 'Mclean Park, Napier', 'Bay Oval, Mount Maunganui', 'Sky Stadium, Wellington', 'Adelaide Oval, Adelaide', 'Melbourne Cricket Ground, Melbourne', 'Adelaide Oval, Adelaide', 'Perth Stadium, Perth', 'Sydney Cricket Ground, Sydney', 'Melbourne Cricket Ground, Melbourne', 'The Gabba, Brisbane', 'The Gabba, Brisbane', 'Sylhet International Cricket Stadium, Sylhet', 'Sylhet International Cricket Stadium, Sylhet', 'Arun Jaitley Stadium, Delhi', 'Sylhet International Cricket Stadium, Sylhet', 'JSCA International Stadium Complex, Ranchi', 'Sylhet International Cricket Stadium, Sylhet', 'Sylhet International Cricket Stadium, Sylhet', 'Bharat Ratna Shri Atal Bihari Vajpayee Ekana Cricket Stadium, Lucknow', 'Holkar Cricket Stadium, Indore', 'Sylhet Outer Cricket Stadium, Sylhet', 'Sylhet Outer Cricket Stadium, Sylhet', 'Barsapara Cricket Stadium, Guwahati', 'Sylhet Outer Cricket Stadium, Sylhet', 'Greenfield International Stadium, Thiruvananthapuram', 'M A Chidambaram Stadium, Chennai', 'Rajiv Gandhi International Stadium, Hyderabad', 'M A Chidambaram Stadium, Chennai', \"Lord's Cricket Ground, London\", 'Vidarbha Cricket Association Stadium, Nagpur', 'M A Chidambaram Stadium, Chennai', 'St Lawrence Ground, Canterbury', 'Punjab Cricket Association IS Bindra Stadium, Mohali', 'County Ground, Hove', 'County Ground, Bristol', 'M.Chinnaswamy Stadium, Bangalore', 'County Ground, Derby', 'Riverside Ground, Chester-le-Street', 'Dubai International Cricket Stadium, Dubai', 'KSCA Stadium, Hubli', 'Dubai International Cricket Stadium, Dubai', 'Dubai International Cricket Stadium, Dubai', 'M.Chinnaswamy Stadium, Bangalore', 'Dubai International Cricket Stadium, Dubai', 'Dubai International Cricket Stadium, Dubai']\n",
      "211\n"
     ]
    }
   ],
   "source": [
    "print(place)\n",
    "print(len(place))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "80e08d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Date\n",
    "    \n",
    "date = []\n",
    "date_elements = driver.find_elements(By.XPATH,\"//div[@class='match-dates ng-binding']\")\n",
    "time.sleep(2)\n",
    "for i in date_elements:\n",
    "    date.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9afdabaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14 OCTOBER, 2023', '19 OCTOBER, 2023', '22 OCTOBER, 2023', '29 OCTOBER, 2023', '2 NOVEMBER, 2023', '5 NOVEMBER, 2023', '12 NOVEMBER, 2023', '13 NOVEMBER, 2023', '13 NOVEMBER, 2023', '15 NOVEMBER, 2023', '15 NOVEMBER, 2023', '17 NOVEMBER, 2023', '17 NOVEMBER, 2023', '20 NOVEMBER, 2023', '20 NOVEMBER, 2023', '22 NOVEMBER, 2023', '22 NOVEMBER, 2023', '23 NOVEMBER, 2023', '24 NOVEMBER, 2023', '24 NOVEMBER, 2023', '26 NOVEMBER, 2023', '27 NOVEMBER, 2023', '27 NOVEMBER, 2023', '28 NOVEMBER, 2023', '1 DECEMBER, 2023', '3 DECEMBER, 2023', '10 DECEMBER, 2023', '12 DECEMBER, 2023', '14 DECEMBER, 2023', '17 DECEMBER, 2023', '19 DECEMBER, 2023', '21 DECEMBER, 2023', '26 DECEMBER, 2023', '3 JANUARY, 2024', '11 JANUARY, 2024', '14 JANUARY, 2024', '17 JANUARY, 2024', '25 JANUARY, 2024', '2 FEBRUARY, 2024', '15 FEBRUARY, 2024', '23 FEBRUARY, 2024', '7 MARCH, 2024', '11 OCTOBER, 2023', '8 OCTOBER, 2023', '7 OCTOBER, 2023', '6 OCTOBER, 2023', '3 OCTOBER, 2023', '3 OCTOBER, 2023', '30 SEPTEMBER, 2023', '27 SEPTEMBER, 2023', '25 SEPTEMBER, 2023', '24 SEPTEMBER, 2023', '24 SEPTEMBER, 2023', '22 SEPTEMBER, 2023', '21 SEPTEMBER, 2023', '17 SEPTEMBER, 2023', '15 SEPTEMBER, 2023', '12 SEPTEMBER, 2023', '10 SEPTEMBER, 2023', '4 SEPTEMBER, 2023', '2 SEPTEMBER, 2023', '23 AUGUST, 2023', '20 AUGUST, 2023', '18 AUGUST, 2023', '13 AUGUST, 2023', '12 AUGUST, 2023', '8 AUGUST, 2023', '6 AUGUST, 2023', '3 AUGUST, 2023', '1 AUGUST, 2023', '29 JULY, 2023', '27 JULY, 2023', '23 JULY, 2023', '22 JULY, 2023', '21 JULY, 2023', '21 JULY, 2023', '20 JULY, 2023', '19 JULY, 2023', '19 JULY, 2023', '19 JULY, 2023', '18 JULY, 2023', '18 JULY, 2023', '17 JULY, 2023', '17 JULY, 2023', '16 JULY, 2023', '15 JULY, 2023', '15 JULY, 2023', '14 JULY, 2023', '14 JULY, 2023', '13 JULY, 2023', '13 JULY, 2023', '13 JULY, 2023', '12 JULY, 2023', '11 JULY, 2023', '9 JULY, 2023', '21 JUNE, 2023', '20 JUNE, 2023', '19 JUNE, 2023', '17 JUNE, 2023', '15 JUNE, 2023', '13 JUNE, 2023', '7 JUNE, 2023', '22 MARCH, 2023', '19 MARCH, 2023', '17 MARCH, 2023', '9 MARCH, 2023', '1 MARCH, 2023', '23 FEBRUARY, 2023', '20 FEBRUARY, 2023', '18 FEBRUARY, 2023', '17 FEBRUARY, 2023', '15 FEBRUARY, 2023', '12 FEBRUARY, 2023', '9 FEBRUARY, 2023', '2 FEBRUARY, 2023', '1 FEBRUARY, 2023', '30 JANUARY, 2023', '29 JANUARY, 2023', '29 JANUARY, 2023', '28 JANUARY, 2023', '27 JANUARY, 2023', '27 JANUARY, 2023', '24 JANUARY, 2023', '23 JANUARY, 2023', '22 JANUARY, 2023', '21 JANUARY, 2023', '21 JANUARY, 2023', '19 JANUARY, 2023', '18 JANUARY, 2023', '18 JANUARY, 2023', '16 JANUARY, 2023', '15 JANUARY, 2023', '14 JANUARY, 2023', '12 JANUARY, 2023', '10 JANUARY, 2023', '7 JANUARY, 2023', '5 JANUARY, 2023', '4 JANUARY, 2023', '3 JANUARY, 2023', '3 JANUARY, 2023', '2 JANUARY, 2023', '31 DECEMBER, 2022', '29 DECEMBER, 2022', '27 DECEMBER, 2022', '22 DECEMBER, 2022', '20 DECEMBER, 2022', '17 DECEMBER, 2022', '14 DECEMBER, 2022', '14 DECEMBER, 2022', '11 DECEMBER, 2022', '10 DECEMBER, 2022', '9 DECEMBER, 2022', '7 DECEMBER, 2022', '6 DECEMBER, 2022', '6 DECEMBER, 2022', '4 DECEMBER, 2022', '4 DECEMBER, 2022', '1 DECEMBER, 2022', '30 NOVEMBER, 2022', '29 NOVEMBER, 2022', '29 NOVEMBER, 2022', '27 NOVEMBER, 2022', '27 NOVEMBER, 2022', '25 NOVEMBER, 2022', '24 NOVEMBER, 2022', '22 NOVEMBER, 2022', '22 NOVEMBER, 2022', '20 NOVEMBER, 2022', '18 NOVEMBER, 2022', '10 NOVEMBER, 2022', '6 NOVEMBER, 2022', '2 NOVEMBER, 2022', '30 OCTOBER, 2022', '27 OCTOBER, 2022', '23 OCTOBER, 2022', '19 OCTOBER, 2022', '17 OCTOBER, 2022', '15 OCTOBER, 2022', '13 OCTOBER, 2022', '11 OCTOBER, 2022', '10 OCTOBER, 2022', '9 OCTOBER, 2022', '8 OCTOBER, 2022', '7 OCTOBER, 2022', '6 OCTOBER, 2022', '4 OCTOBER, 2022', '4 OCTOBER, 2022', '3 OCTOBER, 2022', '2 OCTOBER, 2022', '1 OCTOBER, 2022', '28 SEPTEMBER, 2022', '27 SEPTEMBER, 2022', '25 SEPTEMBER, 2022', '25 SEPTEMBER, 2022', '24 SEPTEMBER, 2022', '23 SEPTEMBER, 2022', '22 SEPTEMBER, 2022', '21 SEPTEMBER, 2022', '20 SEPTEMBER, 2022', '18 SEPTEMBER, 2022', '15 SEPTEMBER, 2022', '15 SEPTEMBER, 2022', '13 SEPTEMBER, 2022', '10 SEPTEMBER, 2022', '8 SEPTEMBER, 2022', '8 SEPTEMBER, 2022', '6 SEPTEMBER, 2022', '4 SEPTEMBER, 2022', '1 SEPTEMBER, 2022', '31 AUGUST, 2022', '28 AUGUST, 2022']\n",
      "211\n"
     ]
    }
   ],
   "source": [
    "print(date)\n",
    "print(len(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dba62f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Time\n",
    "    \n",
    "IST = []\n",
    "IST_elements = driver.find_elements(By.XPATH,\"//div[@class='match-time no-margin ng-binding']\")\n",
    "time.sleep(2)\n",
    "\n",
    "for i in IST_elements:\n",
    "    IST.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a8b081aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2:00 PM IST', '2:00 PM IST', '2:00 PM IST', '2:00 PM IST', '2:00 PM IST', '2:00 PM IST', '2:00 PM IST', '9:00 AM IST', '9:00 AM IST', '9:00 AM IST', '9:00 AM IST', '9:00 AM IST', '9:00 AM IST', '9:00 AM IST', '9:00 AM IST', '9:00 AM IST', '9:00 AM IST', '7:00 PM IST', '9:00 AM IST', '9:00 AM IST', '7:00 PM IST', '9:00 AM IST', '9:00 AM IST', '7:00 PM IST', '7:00 PM IST', '7:00 PM IST', '9:30 PM IST', '9:30 PM IST', '9:30 PM IST', '2:00 PM IST', '2:00 PM IST', '2:00 PM IST', '1:30 PM IST', '1:30 PM IST', '7:00 PM IST', '7:00 PM IST', '7:00 PM IST', '9:30 AM IST', '9:30 AM IST', '9:30 AM IST', '9:30 AM IST', '9:30 AM IST', '2:00 PM IST', '2:00 PM IST', '11:30 AM IST', '6:30 AM IST', '2:00 PM IST', '6:30 AM IST', '2:00 PM IST', '1:30 PM IST', '11:30 AM IST', '1:30 PM IST', '6:30 AM IST', '1:30 PM IST', '6:30 AM IST', '3:00 PM IST', '3:00 PM IST', '3:00 PM IST', '3:00 PM IST', '3:00 PM IST', '3:00 PM IST', '7:30 PM IST', '7:30 PM IST', '7:30 PM IST', '8:00 PM IST', '8:00 PM IST', '8:00 PM IST', '8:00 PM IST', '8:00 PM IST', '7:00 PM IST', '7:00 PM IST', '7:00 PM IST', '2:00 PM IST', '9:00 AM IST', '2:00 PM IST', '10:00 AM IST', '7:30 PM IST', '2:00 PM IST', '10:00 AM IST', '9:00 AM IST', '2:00 PM IST', '10:00 AM IST', '2:00 PM IST', '10:00 AM IST', '9:00 AM IST', '10:00 AM IST', '10:00 AM IST', '10:00 AM IST', '10:00 AM IST', '1:30 PM IST', '10:00 AM IST', '10:00 AM IST', '7:30 PM IST', '1:30 PM IST', '1:30 PM IST', '9:00 AM IST', '6:30 AM IST', '6:30 AM IST', '11:00 AM IST', '11:00 AM IST', '11:00 AM IST', '3:00 PM IST', '1:30 PM IST', '1:30 PM IST', '1:30 PM IST', '9:30 AM IST', '9:30 AM IST', '6:30 PM IST', '6:30 PM IST', '6:30 PM IST', '9:30 AM IST', '6:30 PM IST', '6:30 PM IST', '9:30 AM IST', '3:00 PM IST', '7:00 PM IST', '3:00 PM IST', '7:00 PM IST', '1:45 PM IST', '7:00 PM IST', '7:00 PM IST', '10:00 AM IST', '1:30 PM IST', '7:00 PM IST', '1:45 PM IST', '1:45 PM IST', '1:30 PM IST', '7:00 PM IST', '1:45 PM IST', '1:30 PM IST', '10:00 AM IST', '1:30 PM IST', '1:45 PM IST', '1:30 PM IST', '1:30 PM IST', '7:00 PM IST', '7:00 PM IST', '10:00 AM IST', '7:00 PM IST', '10:00 AM IST', '1:45 PM IST', '10:00 AM IST', '1:45 PM IST', '10:00 AM IST', '9:00 AM IST', '7:00 PM IST', '7:00 PM IST', '7:00 PM IST', '9:00 AM IST', '7:00 PM IST', '11:30 AM IST', '7:00 PM IST', '11:30 AM IST', '1:00 PM IST', '9:00 AM IST', '1:00 PM IST', '11:30 AM IST', '1:00 PM IST', '7:00 AM IST', '1:00 PM IST', '9:00 AM IST', '1:00 PM IST', '7:00 AM IST', '7:00 AM IST', '1:00 PM IST', '1:00 PM IST', '12:00 PM IST', '12:00 PM IST', '12:00 PM IST', '1:30 PM IST', '1:30 PM IST', '1:30 PM IST', '4:30 PM IST', '12:39 PM IST', '1:30 PM IST', '1:30 PM IST', '9:30 AM IST', '1:00 PM IST', '8:30 AM IST', '1:30 PM IST', '1:00 PM IST', '1:30 PM IST', '1:00 PM IST', '1:00 PM IST', '2:00 PM IST', '7:00 PM IST', '1:00 PM IST', '1:00 PM IST', '7:00 PM IST', '1:00 PM IST', '7:00 PM IST', '9:00 AM IST', '7:00 PM IST', '9:00 AM IST', '3:30 PM IST', '7:00 PM IST', '9:00 AM IST', '5:30 PM IST', '7:00 PM IST', '3:30 PM IST', '11:00 PM IST', '9:30 AM IST', '10:30 PM IST', '11:30 PM IST', '7:30 PM IST', '9:30 AM IST', '7:30 PM IST', '7:30 PM IST', '9:30 AM IST', '7:30 PM IST', '7:30 PM IST']\n",
      "211\n"
     ]
    }
   ],
   "source": [
    "print(IST)\n",
    "print(len(IST))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4c1e36",
   "metadata": {},
   "source": [
    "## Q2 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4c22b58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Narendra Modi Stadium, Ahmedabad</td>\n",
       "      <td>14 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "      <td>19 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium, ...</td>\n",
       "      <td>22 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Bharat Ratna Shri Atal Bihari Vajpayee Ekana C...</td>\n",
       "      <td>29 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>2 NOVEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>6 SEPTEMBER, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>4 SEPTEMBER, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NEW ZEALAND A TOUR OF INDIA</td>\n",
       "      <td>M.Chinnaswamy Stadium, Bangalore</td>\n",
       "      <td>1 SEPTEMBER, 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>31 AUGUST, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>28 AUGUST, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Series  \\\n",
       "0        ICC MENS WORLD CUP 2023   \n",
       "1        ICC MENS WORLD CUP 2023   \n",
       "2        ICC MENS WORLD CUP 2023   \n",
       "3        ICC MENS WORLD CUP 2023   \n",
       "4        ICC MENS WORLD CUP 2023   \n",
       "..                           ...   \n",
       "206                ASIA CUP 2022   \n",
       "207                ASIA CUP 2022   \n",
       "208  NEW ZEALAND A TOUR OF INDIA   \n",
       "209                ASIA CUP 2022   \n",
       "210                ASIA CUP 2022   \n",
       "\n",
       "                                                 Place               Date  \\\n",
       "0                     Narendra Modi Stadium, Ahmedabad   14 OCTOBER, 2023   \n",
       "1        Maharashtra Cricket Association Stadium, Pune   19 OCTOBER, 2023   \n",
       "2    Himachal Pradesh Cricket Association Stadium, ...   22 OCTOBER, 2023   \n",
       "3    Bharat Ratna Shri Atal Bihari Vajpayee Ekana C...   29 OCTOBER, 2023   \n",
       "4                             Wankhede Stadium, Mumbai   2 NOVEMBER, 2023   \n",
       "..                                                 ...                ...   \n",
       "206         Dubai International Cricket Stadium, Dubai  6 SEPTEMBER, 2022   \n",
       "207         Dubai International Cricket Stadium, Dubai  4 SEPTEMBER, 2022   \n",
       "208                   M.Chinnaswamy Stadium, Bangalore  1 SEPTEMBER, 2022   \n",
       "209         Dubai International Cricket Stadium, Dubai    31 AUGUST, 2022   \n",
       "210         Dubai International Cricket Stadium, Dubai    28 AUGUST, 2022   \n",
       "\n",
       "            Time  \n",
       "0    2:00 PM IST  \n",
       "1    2:00 PM IST  \n",
       "2    2:00 PM IST  \n",
       "3    2:00 PM IST  \n",
       "4    2:00 PM IST  \n",
       "..           ...  \n",
       "206  7:30 PM IST  \n",
       "207  7:30 PM IST  \n",
       "208  9:30 AM IST  \n",
       "209  7:30 PM IST  \n",
       "210  7:30 PM IST  \n",
       "\n",
       "[211 rows x 4 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'Series': series,\n",
    "    'Place': place,\n",
    "    'Date': date,\n",
    "    'Time': IST,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf3b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13ea01ea",
   "metadata": {},
   "source": [
    "## Q3 Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "Url = http://statisticstimes.com/ \n",
    "You have to find following details: \n",
    "A) Rank \n",
    "B) State \n",
    "C) GSDP(18-19)- at current prices \n",
    "D) GSDP(19-20)- at current prices \n",
    "E) Share(18-19) \n",
    "F) GDP($ billion) \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cb03e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    driver = webdriver.Edge()\n",
    "    driver.get('http://statisticstimes.com/')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    button_economy = driver.find_element(By.XPATH, \"/html/body/div[2]/div[1]/div[2]/div[2]/button\")  \n",
    "    button_economy.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    button_India = driver.find_element(By.XPATH, \"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\")  \n",
    "    button_India.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    button_GDP = driver.find_element(By.XPATH, \"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")  \n",
    "    button_GDP.click()\n",
    "    \n",
    "\n",
    "except NoSuchElementException as e:\n",
    "    print(\"Exception Raised \", e)\n",
    "    print(\"Refreshing the Page \")\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5e09d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbody = driver.find_element(By.XPATH, '/html/body/div[3]/div[2]/div[5]/div[1]/div/table')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "data2 = []\n",
    "for tr in tbody.find_elements(By.XPATH, \"//tr\")[1:]:\n",
    "    r = [td.text.replace(\"\\n\", ' ') for td in tr.find_elements(By.XPATH, './/td')]\n",
    "    if(len(r) == 8):\n",
    "        rank = r[0]\n",
    "        state = r[1]\n",
    "        GSDP_18_19 = r[3]\n",
    "        GSDP_19_20  = r[2]\n",
    "        Share_18_19 = r[4]\n",
    "        GDP_billion = r[5]\n",
    "        data2.append([rank, state, GSDP_18_19, GSDP_19_20, Share_18_19,GDP_billion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83a8c89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', 'Maharashtra', '2,632,792', '-', '13.94%', '399.921'], ['2', 'Tamil Nadu', '1,630,208', '1,845,853', '8.63%', '247.629'], ['3', 'Uttar Pradesh', '1,584,764', '1,687,818', '8.39%', '240.726'], ['4', 'Gujarat', '1,502,899', '-', '7.96%', '228.290'], ['5', 'Karnataka', '1,493,127', '1,631,977', '7.91%', '226.806'], ['6', 'West Bengal', '1,089,898', '1,253,832', '5.77%', '165.556'], ['7', 'Rajasthan', '942,586', '1,020,989', '4.99%', '143.179'], ['8', 'Andhra Pradesh', '862,957', '972,782', '4.57%', '131.083'], ['9', 'Telangana', '861,031', '969,604', '4.56%', '130.791'], ['10', 'Madhya Pradesh', '809,592', '906,672', '4.29%', '122.977'], ['11', 'Kerala', '781,653', '-', '4.14%', '118.733'], ['12', 'Delhi', '774,870', '856,112', '4.10%', '117.703'], ['13', 'Haryana', '734,163', '831,610', '3.89%', '111.519'], ['14', 'Bihar', '530,363', '611,804', '2.81%', '80.562'], ['15', 'Punjab', '526,376', '574,760', '2.79%', '79.957'], ['16', 'Odisha', '487,805', '521,275', '2.58%', '74.098'], ['17', 'Assam', '315,881', '-', '1.67%', '47.982'], ['18', 'Chhattisgarh', '304,063', '329,180', '1.61%', '46.187'], ['19', 'Jharkhand', '297,204', '328,598', '1.57%', '45.145'], ['20', 'Uttarakhand', '245,895', '-', '1.30%', '37.351'], ['21', 'Jammu & Kashmir', '155,956', '-', '0.83%', '23.690'], ['22', 'Himachal Pradesh', '153,845', '165,472', '0.81%', '23.369'], ['23', 'Goa', '73,170', '80,449', '0.39%', '11.115'], ['24', 'Tripura', '49,845', '55,984', '0.26%', '7.571'], ['25', 'Chandigarh', '42,114', '-', '0.22%', '6.397'], ['26', 'Puducherry', '34,433', '38,253', '0.18%', '5.230'], ['27', 'Meghalaya', '33,481', '36,572', '0.18%', '5.086'], ['28', 'Sikkim', '28,723', '32,496', '0.15%', '4.363'], ['29', 'Manipur', '27,870', '31,790', '0.15%', '4.233'], ['30', 'Nagaland', '27,283', '-', '0.14%', '4.144'], ['31', 'Arunachal Pradesh', '24,603', '-', '0.13%', '3.737'], ['32', 'Mizoram', '22,287', '26,503', '0.12%', '3.385'], ['33', 'Andaman & Nicobar Islands', '-', '-', '-', '-'], ['', 'India', '18,886,957', '20,351,013', '', '2,869']]\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "print(data2)\n",
    "print(len(data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58892a37",
   "metadata": {},
   "source": [
    "## Q3 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f70ee799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                      State GSDP(18-19)- at current prices  \\\n",
      "0     1                Maharashtra                      2,632,792   \n",
      "1     2                 Tamil Nadu                      1,630,208   \n",
      "2     3              Uttar Pradesh                      1,584,764   \n",
      "3     4                    Gujarat                      1,502,899   \n",
      "4     5                  Karnataka                      1,493,127   \n",
      "5     6                West Bengal                      1,089,898   \n",
      "6     7                  Rajasthan                        942,586   \n",
      "7     8             Andhra Pradesh                        862,957   \n",
      "8     9                  Telangana                        861,031   \n",
      "9    10             Madhya Pradesh                        809,592   \n",
      "10   11                     Kerala                        781,653   \n",
      "11   12                      Delhi                        774,870   \n",
      "12   13                    Haryana                        734,163   \n",
      "13   14                      Bihar                        530,363   \n",
      "14   15                     Punjab                        526,376   \n",
      "15   16                     Odisha                        487,805   \n",
      "16   17                      Assam                        315,881   \n",
      "17   18               Chhattisgarh                        304,063   \n",
      "18   19                  Jharkhand                        297,204   \n",
      "19   20                Uttarakhand                        245,895   \n",
      "20   21            Jammu & Kashmir                        155,956   \n",
      "21   22           Himachal Pradesh                        153,845   \n",
      "22   23                        Goa                         73,170   \n",
      "23   24                    Tripura                         49,845   \n",
      "24   25                 Chandigarh                         42,114   \n",
      "25   26                 Puducherry                         34,433   \n",
      "26   27                  Meghalaya                         33,481   \n",
      "27   28                     Sikkim                         28,723   \n",
      "28   29                    Manipur                         27,870   \n",
      "29   30                   Nagaland                         27,283   \n",
      "30   31          Arunachal Pradesh                         24,603   \n",
      "31   32                    Mizoram                         22,287   \n",
      "32   33  Andaman & Nicobar Islands                              -   \n",
      "33                           India                     18,886,957   \n",
      "\n",
      "   GSDP(19-20)- at current prices Share(18-19) GDP($ billion)  \n",
      "0                               -       13.94%        399.921  \n",
      "1                       1,845,853        8.63%        247.629  \n",
      "2                       1,687,818        8.39%        240.726  \n",
      "3                               -        7.96%        228.290  \n",
      "4                       1,631,977        7.91%        226.806  \n",
      "5                       1,253,832        5.77%        165.556  \n",
      "6                       1,020,989        4.99%        143.179  \n",
      "7                         972,782        4.57%        131.083  \n",
      "8                         969,604        4.56%        130.791  \n",
      "9                         906,672        4.29%        122.977  \n",
      "10                              -        4.14%        118.733  \n",
      "11                        856,112        4.10%        117.703  \n",
      "12                        831,610        3.89%        111.519  \n",
      "13                        611,804        2.81%         80.562  \n",
      "14                        574,760        2.79%         79.957  \n",
      "15                        521,275        2.58%         74.098  \n",
      "16                              -        1.67%         47.982  \n",
      "17                        329,180        1.61%         46.187  \n",
      "18                        328,598        1.57%         45.145  \n",
      "19                              -        1.30%         37.351  \n",
      "20                              -        0.83%         23.690  \n",
      "21                        165,472        0.81%         23.369  \n",
      "22                         80,449        0.39%         11.115  \n",
      "23                         55,984        0.26%          7.571  \n",
      "24                              -        0.22%          6.397  \n",
      "25                         38,253        0.18%          5.230  \n",
      "26                         36,572        0.18%          5.086  \n",
      "27                         32,496        0.15%          4.363  \n",
      "28                         31,790        0.15%          4.233  \n",
      "29                              -        0.14%          4.144  \n",
      "30                              -        0.13%          3.737  \n",
      "31                         26,503        0.12%          3.385  \n",
      "32                              -            -              -  \n",
      "33                     20,351,013                       2,869  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Create a DataFrame\n",
    "df = pd.DataFrame(data2, columns=['Rank', 'State', 'GSDP(18-19)- at current prices', 'GSDP(19-20)- at current prices', 'Share(18-19)', 'GDP($ billion)'])\n",
    "\n",
    "#Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24224c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8576c2f",
   "metadata": {},
   "source": [
    "## Q4 Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/ \n",
    "You have to find the following details: \n",
    "A) Repository title \n",
    "B) Repository description \n",
    "C) Contributors count \n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6910b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()\n",
    "driver.get('https://github.com/')\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d6066294",
   "metadata": {},
   "outputs": [],
   "source": [
    "button_general = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/header/div/div[1]/div[2]/button\")  \n",
    "button_general.click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "50c5527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "button_open_source = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\")  \n",
    "button_open_source.click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cf81b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "button_trending = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a\")  \n",
    "button_trending.click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9c928556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ByteByteGoHq / system-design-101', 'OpenBMB / XAgent', 'ionic-team / ionic-framework', 'cpacker / MemGPT', 'Alex313031 / thorium', 'cloudcommunity / Free-Certifications', 'DarkFlippers / unleashed-firmware', 'TheRealJoelmatic / RemoveAdblockThing', 'refinedev / refine', 'PWhiddy / PokemonRedExperiments', 'Alex313031 / Thorium-Win', 'imteekay / programming-language-research', 'devfullcycle / imersao15', 'langchain-ai / langchain', 'Azure-Samples / azure-search-openai-demo', 'felipemotarocha / fullstackweek-store', 'Azure / azure-sdk-for-java', 'trufflesecurity / trufflehog', 'Kong / kong', 'nextauthjs / next-auth', 't3-oss / create-t3-app', 'mkkellogg / GaussianSplats3D', 'Orange-Cyberdefense / GOAD', 'cloudflare / workers-sdk', 'nodejs / node']\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "#Scrape Repository title,Repository description,Contributors count,Language used\n",
    "\n",
    "Repository_title = []\n",
    "repository_title_elements = driver.find_elements(By.XPATH, \"//h2[@class='h3 lh-condensed']\")\n",
    "\n",
    "for i in repository_title_elements:\n",
    "    Repository_title.append(i.text)\n",
    "    \n",
    "print(Repository_title)\n",
    "print(len(Repository_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ff9ff749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Explain complex systems using visuals and simple terms. Help you prepare for system design interviews.', 'An Autonomous LLM Agent for Complex Task Solving', 'A powerful cross-platform UI toolkit for building native-quality iOS, Android, and Progressive Web Apps with HTML, CSS, and JavaScript.', 'Teaching LLMs memory management for unbounded context 📚🦙', 'Chromium fork named after radioactive element No. 90. Windows and MacOS/Raspi/Android/Special builds are in different repositories, links are towards the top of the README.md.', 'A curated list of free courses & certifications.', 'Flipper Zero Unleashed Firmware', 'Removes The \"Ad blocker are not allowed on Youtube\"', 'Build your React-based CRUD applications, without constraints. 🌟 Star to support our work!', 'Playing Pokemon Red with Reinforcement Learning', 'Chromium fork for Windows named after radioactive element No. 90; Windows builds of https://github.com/Alex313031/Thorium', 'Programming Language Research, Applied PLT & Compilers', '⚡ Building applications with LLMs through composability ⚡', 'A sample app for the Retrieval-Augmented Generation pattern running in Azure, using Azure Cognitive Search for retrieval and Azure OpenAI large language models to power ChatGPT-style and Q&A experiences.', 'This repository is for active development of the Azure SDK for Java. For consumers of the SDK we recommend visiting our public developer docs at https://docs.microsoft.com/java/azure/ or our versioned developer docs at https://azure.github.io/azure-sdk-for-java.', 'Find and verify credentials', '🦍 The Cloud-Native API Gateway', 'Authentication for the Web.', 'The best way to start a full-stack, typesafe Next.js app', 'Three.js-based implementation of the 3D Gaussian splat viewer', 'game of active directory', '⛅️ Home to Wrangler, the CLI for Cloudflare Workers®', 'Node.js JavaScript runtime ✨🐢🚀✨']\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "#Scrape Repository title,Repository description,Contributors count,Language used\n",
    "Repository_description = []\n",
    "repository_description_elements = driver.find_elements(By.XPATH, \"//p[@class='col-9 color-fg-muted my-1 pr-4']\")\n",
    "for i in repository_description_elements:\n",
    "    Repository_description.append(i.text)\n",
    "    \n",
    "print(Repository_description)\n",
    "print(len(Repository_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "17f11b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TypeScript', 'TypeScript', 'Python', 'C++', 'C', 'JavaScript', 'TypeScript', 'Jupyter Notebook', 'Batchfile', 'Clojure', 'Go', 'Python', 'Python', 'TypeScript', 'Java', 'Go', 'Lua', 'TypeScript', 'TypeScript', 'JavaScript', 'PowerShell', 'TypeScript', 'JavaScript']\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "#Scrape Repository title,Repository description,Contributors count,Language used\n",
    "\n",
    "Language_used = []\n",
    "language_used_elements = driver.find_elements(By.XPATH, \"//span[@class='d-inline-block ml-0 mr-3']\")\n",
    "\n",
    "for i in language_used_elements:\n",
    "    Language_used.append(i.text)\n",
    "    \n",
    "print(Language_used)\n",
    "print(len(Language_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "748e7cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10,844', '1,130', '1,046', '67', '49,507', '13,680', '2,889', '186', '1,909', '55', '8,719', '837', '11,424', '1,078', '1,395', '45', '15,294', '1,229', '4,209', '282', '461', '18', '460', '23', '75', '38', '65,190', '9,288', '3,844', '2,232', '89', '14', '2,033', '1,887', '12,351', '1,446', '36,075', '4,627', '19,248', '2,372', '20,533', '873', '205', '22', '3,040', '434', '1,750', '379', '98,720', '27,382']\n",
      "50\n",
      "['1,130', '67', '13,680', '186', '55', '837', '1,078', '45', '1,229', '282', '18', '23', '38', '9,288', '2,232', '14', '1,887', '1,446', '4,627', '2,372', '873', '22', '434', '379', '27,382']\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "#Scrape Repository title,Repository description,Contributors count,Language used\n",
    "\n",
    "all_5 = []\n",
    "all_5_Elements = driver.find_elements(By.XPATH, \"//a[@class='Link Link--muted d-inline-block mr-3']\")\n",
    "\n",
    "Contributors_Count = []\n",
    "\n",
    "for i in all_5_Elements:\n",
    "    all_5.append(i.text)\n",
    "    \n",
    "for i in range(1, len(all_5), 2):\n",
    "    Contributors_Count.append(all_5[i])\n",
    "    \n",
    "print(all_5)\n",
    "print(len(all_5))\n",
    "\n",
    "print(Contributors_Count)\n",
    "print(len(Contributors_Count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1273fca6",
   "metadata": {},
   "source": [
    "## Q4 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "478ae9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Language Used</th>\n",
       "      <th>Contributors Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ByteByteGoHq / system-design-101</td>\n",
       "      <td>Explain complex systems using visuals and simp...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>1,130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OpenBMB / XAgent</td>\n",
       "      <td>An Autonomous LLM Agent for Complex Task Solving</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ionic-team / ionic-framework</td>\n",
       "      <td>A powerful cross-platform UI toolkit for build...</td>\n",
       "      <td>Python</td>\n",
       "      <td>13,680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cpacker / MemGPT</td>\n",
       "      <td>Teaching LLMs memory management for unbounded ...</td>\n",
       "      <td>C++</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alex313031 / thorium</td>\n",
       "      <td>Chromium fork named after radioactive element ...</td>\n",
       "      <td>C</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cloudcommunity / Free-Certifications</td>\n",
       "      <td>A curated list of free courses &amp; certifications.</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DarkFlippers / unleashed-firmware</td>\n",
       "      <td>Flipper Zero Unleashed Firmware</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>1,078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TheRealJoelmatic / RemoveAdblockThing</td>\n",
       "      <td>Removes The \"Ad blocker are not allowed on You...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>refinedev / refine</td>\n",
       "      <td>Build your React-based CRUD applications, with...</td>\n",
       "      <td>Batchfile</td>\n",
       "      <td>1,229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PWhiddy / PokemonRedExperiments</td>\n",
       "      <td>Playing Pokemon Red with Reinforcement Learning</td>\n",
       "      <td>Clojure</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alex313031 / Thorium-Win</td>\n",
       "      <td>Chromium fork for Windows named after radioact...</td>\n",
       "      <td>Go</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>imteekay / programming-language-research</td>\n",
       "      <td>Programming Language Research, Applied PLT &amp; C...</td>\n",
       "      <td>Python</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>devfullcycle / imersao15</td>\n",
       "      <td>⚡ Building applications with LLMs through comp...</td>\n",
       "      <td>Python</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>langchain-ai / langchain</td>\n",
       "      <td>A sample app for the Retrieval-Augmented Gener...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>9,288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Azure-Samples / azure-search-openai-demo</td>\n",
       "      <td>This repository is for active development of t...</td>\n",
       "      <td>Java</td>\n",
       "      <td>2,232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>felipemotarocha / fullstackweek-store</td>\n",
       "      <td>Find and verify credentials</td>\n",
       "      <td>Go</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Azure / azure-sdk-for-java</td>\n",
       "      <td>🦍 The Cloud-Native API Gateway</td>\n",
       "      <td>Lua</td>\n",
       "      <td>1,887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>trufflesecurity / trufflehog</td>\n",
       "      <td>Authentication for the Web.</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>1,446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kong / kong</td>\n",
       "      <td>The best way to start a full-stack, typesafe N...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>4,627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nextauthjs / next-auth</td>\n",
       "      <td>Three.js-based implementation of the 3D Gaussi...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>2,372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>t3-oss / create-t3-app</td>\n",
       "      <td>game of active directory</td>\n",
       "      <td>PowerShell</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mkkellogg / GaussianSplats3D</td>\n",
       "      <td>⛅️ Home to Wrangler, the CLI for Cloudflare Wo...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Repository Title  \\\n",
       "0           ByteByteGoHq / system-design-101   \n",
       "1                           OpenBMB / XAgent   \n",
       "2               ionic-team / ionic-framework   \n",
       "3                           cpacker / MemGPT   \n",
       "4                       Alex313031 / thorium   \n",
       "5       cloudcommunity / Free-Certifications   \n",
       "6          DarkFlippers / unleashed-firmware   \n",
       "7      TheRealJoelmatic / RemoveAdblockThing   \n",
       "8                         refinedev / refine   \n",
       "9            PWhiddy / PokemonRedExperiments   \n",
       "10                  Alex313031 / Thorium-Win   \n",
       "11  imteekay / programming-language-research   \n",
       "12                  devfullcycle / imersao15   \n",
       "13                  langchain-ai / langchain   \n",
       "14  Azure-Samples / azure-search-openai-demo   \n",
       "15     felipemotarocha / fullstackweek-store   \n",
       "16                Azure / azure-sdk-for-java   \n",
       "17              trufflesecurity / trufflehog   \n",
       "18                               Kong / kong   \n",
       "19                    nextauthjs / next-auth   \n",
       "20                    t3-oss / create-t3-app   \n",
       "21              mkkellogg / GaussianSplats3D   \n",
       "\n",
       "                               Repository Description     Language Used  \\\n",
       "0   Explain complex systems using visuals and simp...        TypeScript   \n",
       "1    An Autonomous LLM Agent for Complex Task Solving        TypeScript   \n",
       "2   A powerful cross-platform UI toolkit for build...            Python   \n",
       "3   Teaching LLMs memory management for unbounded ...               C++   \n",
       "4   Chromium fork named after radioactive element ...                 C   \n",
       "5    A curated list of free courses & certifications.        JavaScript   \n",
       "6                     Flipper Zero Unleashed Firmware        TypeScript   \n",
       "7   Removes The \"Ad blocker are not allowed on You...  Jupyter Notebook   \n",
       "8   Build your React-based CRUD applications, with...         Batchfile   \n",
       "9     Playing Pokemon Red with Reinforcement Learning           Clojure   \n",
       "10  Chromium fork for Windows named after radioact...                Go   \n",
       "11  Programming Language Research, Applied PLT & C...            Python   \n",
       "12  ⚡ Building applications with LLMs through comp...            Python   \n",
       "13  A sample app for the Retrieval-Augmented Gener...        TypeScript   \n",
       "14  This repository is for active development of t...              Java   \n",
       "15                        Find and verify credentials                Go   \n",
       "16                     🦍 The Cloud-Native API Gateway               Lua   \n",
       "17                        Authentication for the Web.        TypeScript   \n",
       "18  The best way to start a full-stack, typesafe N...        TypeScript   \n",
       "19  Three.js-based implementation of the 3D Gaussi...        JavaScript   \n",
       "20                           game of active directory        PowerShell   \n",
       "21  ⛅️ Home to Wrangler, the CLI for Cloudflare Wo...        TypeScript   \n",
       "\n",
       "   Contributors Count  \n",
       "0               1,130  \n",
       "1                  67  \n",
       "2              13,680  \n",
       "3                 186  \n",
       "4                  55  \n",
       "5                 837  \n",
       "6               1,078  \n",
       "7                  45  \n",
       "8               1,229  \n",
       "9                 282  \n",
       "10                 18  \n",
       "11                 23  \n",
       "12                 38  \n",
       "13              9,288  \n",
       "14              2,232  \n",
       "15                 14  \n",
       "16              1,887  \n",
       "17              1,446  \n",
       "18              4,627  \n",
       "19              2,372  \n",
       "20                873  \n",
       "21                 22  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Repository Title':Repository_title[:22],\n",
    "    'Repository Description':Repository_description[:22],\n",
    "    'Language Used':Language_used[:22],\n",
    "    'Contributors Count':Contributors_Count[:22]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82b1ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01276530",
   "metadata": {},
   "source": [
    "## Q5 Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the following details: \n",
    "A) Song name \n",
    "B) Artist name \n",
    "C) Last week rank \n",
    "D) Peak rank \n",
    "E) Weeks on board \n",
    " Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "776dd1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()\n",
    "driver.get('https:/www.billboard.com/')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54a3af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "button_general = driver.find_element(By.XPATH, \"/html/body/div[3]/header/div/div[4]/div/div[1]/div[1]/button\")  \n",
    "button_general.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55b2f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "button_charts = driver.find_element(By.XPATH, \"/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/button\")  \n",
    "button_charts.click()\n",
    "time.sleep(2)\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27f13ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "button_hot_100 = driver.find_element(By.XPATH, \"/html/body/div[3]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a\")  \n",
    "button_hot_100.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1685732e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Paint The Town Red', 'Doja Cat', '1', '1', '9'], ['Snooze', 'SZA', '2', '2', '43'], ['Cruel Summer', 'Taylor Swift', '4', '3', '22'], ['Fast Car', 'Luke Combs', '3', '2', '28'], ['3D', 'Jung Kook & Jack Harlow', '-', '5', '1'], ['I Remember Everything', 'Zach Bryan Featuring Kacey Musgraves', '5', '1', '6'], ['Last Night', 'Morgan Wallen', '6', '1', '36'], ['Fukumean', 'Gunna', '8', '4', '16'], ['Vampire', 'Olivia Rodrigo', '7', '1', '14'], ['Calm Down', 'Rema & Selena Gomez', '9', '3', '57'], ['Dance The Night', 'Dua Lipa', '10', '6', '19'], ['Barbie World', 'Nicki Minaj & Ice Spice With Aqua', '11', '7', '15'], [\"Thinkin' Bout Me\", 'Morgan Wallen', '17', '9', '31'], ['Greedy', 'Tate McRae', '24', '14', '3'], ['Flowers', 'Miley Cyrus', '15', '1', '38'], ['Religiously', 'Bailey Zimmerman', '13', '13', '22'], ['Need A Favor', 'Jelly Roll', '20', '14', '27'], ['Slime You Out', 'Drake Featuring SZA', '12', '1', '3'], ['Bad Idea Right?', 'Olivia Rodrigo', '16', '7', '8'], ['Anti-Hero', 'Taylor Swift', '21', '1', '50'], ['Watermelon Moonshine', 'Lainey Wilson', '29', '21', '15'], ['All My Life', 'Lil Durk Featuring J. Cole', '19', '2', '21'], ['Used To Be Young', 'Miley Cyrus', '22', '8', '6'], ['Kill Bill', 'SZA', '25', '1', '43'], ['Better Place', '*NSYNC', '-', '25', '1'], ['Dial Drunk', 'Noah Kahan With Post Malone', '27', '25', '16'], ['What Was I Made For?', 'Billie Eilish', '28', '14', '12'], ['Good Good', 'Usher, Summer Walker & 21 Savage', '36', '28', '8'], ['What It Is (Block Boy)', 'Doechii Featuring Kodak Black', '32', '29', '22'], ['Rich Men North Of Richmond', 'Oliver Anthony Music', '23', '1', '8'], ['Karma', 'Taylor Swift Featuring Ice Spice', '31', '2', '30'], [\"Creepin'\", 'Metro Boomin, The Weeknd & 21 Savage', '30', '3', '44'], ['Daylight', 'David Kushner', '37', '33', '25'], ['Agora Hills', 'Doja Cat', '18', '18', '2'], ['I Know ?', 'Travis Scott', '35', '11', '10'], ['Try That In A Small Town', 'Jason Aldean', '39', '1', '12'], ['Save Me', 'Jelly Roll With Lainey Wilson', '47', '37', '16'], ['White Horse', 'Chris Stapleton', '57', '31', '11'], ['Peaches & Eggplants', 'Young Nudy Featuring 21 Savage', '38', '33', '18'], ['Meltdown', 'Travis Scott Featuring Drake', '42', '3', '10'], ['Great Gatsby', 'Rod Wave', '33', '30', '3'], ['Qlona', 'Karol G & Peso Pluma', '41', '28', '8'], ['Un Preview', 'Bad Bunny', '65', '43', '2'], ['Lady Gaga', 'Peso Pluma, Gabito Ballesteros & Junior H', '40', '35', '15'], ['Get Him Back!', 'Olivia Rodrigo', '34', '11', '4'], ['Bongos', 'Cardi B & Megan Thee Stallion', '44', '14', '4'], ['Hey Driver', 'Zach Bryan Featuring The War And Treaty', '52', '14', '6'], ['Single Soon', 'Selena Gomez', '49', '19', '6'], ['My Love Mine All Mine', 'Mitski', '76', '49', '2'], [\"Boyz Don't Cry\", 'Rod Wave', '46', '25', '3'], ['Lil Boo Thang', 'Paul Russell', '74', '51', '3'], ['Turks & Caicos', 'Rod Wave Featuring 21 Savage', '51', '24', '3'], [\"Sarah's Place\", 'Zach Bryan Featuring Noah Kahan', '14', '14', '2'], ['LaLa', 'Myke Towers', '59', '43', '13'], [\"Mamaw's House\", 'Thomas Rhett Featuring Morgan Wallen', '-', '55', '1'], ['Strangers', 'Kenya Grace', '63', '56', '3'], ['Seven', 'Jung Kook Featuring Latto', '53', '1', '12'], ['Lose Control', 'Teddy Swims', '67', '58', '8'], ['Call Your Friends', 'Rod Wave', '50', '18', '7'], ['Come See Me', 'Rod Wave', '48', '19', '5'], ['Everything I Love', 'Morgan Wallen', '69', '14', '32'], ['SkeeYee', 'Sexyy Red', '68', '62', '5'], ['Truck Bed', 'HARDY', '73', '55', '16'], ['Mi Ex Tenia Razon', 'Karol G', '58', '22', '8'], ['Tourniquet', 'Zach Bryan', '61', '20', '6'], ['Popular', 'The Weeknd, Playboi Carti & Madonna', '70', '43', '18'], ['Water', 'Tyla', '-', '67', '1'], ['El Amor de Su Vida', 'Grupo Frontera & Grupo Firme', '72', '68', '7'], ['Segun Quien', 'Maluma & Carin Leon', '83', '69', '2'], ['500lbs', 'Lil Tecca', '60', '60', '2'], ['Deli', 'Ice Spice', '82', '41', '11'], ['Telekinesis', 'Travis Scott Featuring SZA & Future', '77', '26', '10'], ['All-American Bitch', 'Olivia Rodrigo', '56', '13', '4'], ['Oh U Went', 'Young Thug Featuring Drake', '85', '19', '15'], ['Standing Room Only', 'Tim McGraw', '96', '61', '5'], ['On My Mama', 'Victoria Monet', '99', '76', '3'], ['Sabor Fresa', 'Fuerza Regida', '79', '26', '15'], ['Johnny Dang', 'That Mexican OT, Paul Wall & DRODi', '87', '65', '12'], ['Tulum', 'Peso Pluma & Grupo Frontera', '78', '43', '14'], ['Stick Season', 'Noah Kahan', '-', '80', '1'], [\"Can't Have Mine\", 'Dylan Scott', '98', '81', '2'], ['Boys Of Faith', 'Zach Bryan Featuring Bon Iver', '26', '26', '2'], ['Shaq & Kobe', 'Rick Ross & Meek Mill', '-', '83', '1'], ['Pretty Little Poison', 'Warren Zeiders', '-', '59', '6'], ['Bipolar', 'Peso Pluma x Jasiel Nunez x Junior H', '89', '60', '4'], ['The Grudge', 'Olivia Rodrigo', '64', '16', '4'], ['HG4', 'Rod Wave', '71', '51', '3'], ['In Your Love', 'Tyler Childers', '90', '43', '10'], ['Stars Like Confetti', 'Dustin Lynch', '-', '89', '1'], ['God Gave Me A Girl', 'Russell Dickerson', '-', '90', '1'], ['Spotless', 'Zach Bryan Featuring The Lumineers', '80', '17', '6'], ['The Secret Recipe', 'Lil Yachty & J. Cole', '-', '92', '1'], ['Oklahoma Smoke Show', 'Zach Bryan', '-', '80', '9'], ['Que Onda', 'Calle 24 x Chino Pacas x Fuerza Regida', '-', '61', '3'], ['FE!N', 'Travis Scott Featuring Playboi Carti', '-', '5', '9'], ['Long Journey', 'Rod Wave', '75', '39', '3'], ['But I Got A Beer In My Hand', 'Luke Bryan', '-', '92', '3'], ['Rubicon', 'Peso Pluma', '-', '63', '12'], ['East Side Of Sorrow', 'Zach Bryan', '95', '18', '6'], ['Where She Goes', 'Bad Bunny', '-', '8', '19']]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Scrape Song name, Artist name, Last week rank, Peak rank, Weeks on board \n",
    "\n",
    "all1 = []\n",
    "all_elements = driver.find_elements(By.XPATH, \"//ul[@class='lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max']\" )\n",
    "\n",
    "for i in all_elements:\n",
    "    all1.append(i.text.split('\\n'))\n",
    "    \n",
    "print(all1)\n",
    "print(len(all1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7e6cb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snooze\n"
     ]
    }
   ],
   "source": [
    "print(all1[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3a99847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Paint The Town Red', 'Doja Cat', '1', '1', '9', 'Snooze', 'SZA', '2', '2', '43', 'Cruel Summer', 'Taylor Swift', '4', '3', '22', 'Fast Car', 'Luke Combs', '3', '2', '28', '3D', 'Jung Kook & Jack Harlow', '-', '5', '1', 'I Remember Everything', 'Zach Bryan Featuring Kacey Musgraves', '5', '1', '6', 'Last Night', 'Morgan Wallen', '6', '1', '36', 'Fukumean', 'Gunna', '8', '4', '16', 'Vampire', 'Olivia Rodrigo', '7', '1', '14', 'Calm Down', 'Rema & Selena Gomez', '9', '3', '57', 'Dance The Night', 'Dua Lipa', '10', '6', '19', 'Barbie World', 'Nicki Minaj & Ice Spice With Aqua', '11', '7', '15', \"Thinkin' Bout Me\", 'Morgan Wallen', '17', '9', '31', 'Greedy', 'Tate McRae', '24', '14', '3', 'Flowers', 'Miley Cyrus', '15', '1', '38', 'Religiously', 'Bailey Zimmerman', '13', '13', '22', 'Need A Favor', 'Jelly Roll', '20', '14', '27', 'Slime You Out', 'Drake Featuring SZA', '12', '1', '3', 'Bad Idea Right?', 'Olivia Rodrigo', '16', '7', '8', 'Anti-Hero', 'Taylor Swift', '21', '1', '50', 'Watermelon Moonshine', 'Lainey Wilson', '29', '21', '15', 'All My Life', 'Lil Durk Featuring J. Cole', '19', '2', '21', 'Used To Be Young', 'Miley Cyrus', '22', '8', '6', 'Kill Bill', 'SZA', '25', '1', '43', 'Better Place', '*NSYNC', '-', '25', '1', 'Dial Drunk', 'Noah Kahan With Post Malone', '27', '25', '16', 'What Was I Made For?', 'Billie Eilish', '28', '14', '12', 'Good Good', 'Usher, Summer Walker & 21 Savage', '36', '28', '8', 'What It Is (Block Boy)', 'Doechii Featuring Kodak Black', '32', '29', '22', 'Rich Men North Of Richmond', 'Oliver Anthony Music', '23', '1', '8', 'Karma', 'Taylor Swift Featuring Ice Spice', '31', '2', '30', \"Creepin'\", 'Metro Boomin, The Weeknd & 21 Savage', '30', '3', '44', 'Daylight', 'David Kushner', '37', '33', '25', 'Agora Hills', 'Doja Cat', '18', '18', '2', 'I Know ?', 'Travis Scott', '35', '11', '10', 'Try That In A Small Town', 'Jason Aldean', '39', '1', '12', 'Save Me', 'Jelly Roll With Lainey Wilson', '47', '37', '16', 'White Horse', 'Chris Stapleton', '57', '31', '11', 'Peaches & Eggplants', 'Young Nudy Featuring 21 Savage', '38', '33', '18', 'Meltdown', 'Travis Scott Featuring Drake', '42', '3', '10', 'Great Gatsby', 'Rod Wave', '33', '30', '3', 'Qlona', 'Karol G & Peso Pluma', '41', '28', '8', 'Un Preview', 'Bad Bunny', '65', '43', '2', 'Lady Gaga', 'Peso Pluma, Gabito Ballesteros & Junior H', '40', '35', '15', 'Get Him Back!', 'Olivia Rodrigo', '34', '11', '4', 'Bongos', 'Cardi B & Megan Thee Stallion', '44', '14', '4', 'Hey Driver', 'Zach Bryan Featuring The War And Treaty', '52', '14', '6', 'Single Soon', 'Selena Gomez', '49', '19', '6', 'My Love Mine All Mine', 'Mitski', '76', '49', '2', \"Boyz Don't Cry\", 'Rod Wave', '46', '25', '3', 'Lil Boo Thang', 'Paul Russell', '74', '51', '3', 'Turks & Caicos', 'Rod Wave Featuring 21 Savage', '51', '24', '3', \"Sarah's Place\", 'Zach Bryan Featuring Noah Kahan', '14', '14', '2', 'LaLa', 'Myke Towers', '59', '43', '13', \"Mamaw's House\", 'Thomas Rhett Featuring Morgan Wallen', '-', '55', '1', 'Strangers', 'Kenya Grace', '63', '56', '3', 'Seven', 'Jung Kook Featuring Latto', '53', '1', '12', 'Lose Control', 'Teddy Swims', '67', '58', '8', 'Call Your Friends', 'Rod Wave', '50', '18', '7', 'Come See Me', 'Rod Wave', '48', '19', '5', 'Everything I Love', 'Morgan Wallen', '69', '14', '32', 'SkeeYee', 'Sexyy Red', '68', '62', '5', 'Truck Bed', 'HARDY', '73', '55', '16', 'Mi Ex Tenia Razon', 'Karol G', '58', '22', '8', 'Tourniquet', 'Zach Bryan', '61', '20', '6', 'Popular', 'The Weeknd, Playboi Carti & Madonna', '70', '43', '18', 'Water', 'Tyla', '-', '67', '1', 'El Amor de Su Vida', 'Grupo Frontera & Grupo Firme', '72', '68', '7', 'Segun Quien', 'Maluma & Carin Leon', '83', '69', '2', '500lbs', 'Lil Tecca', '60', '60', '2', 'Deli', 'Ice Spice', '82', '41', '11', 'Telekinesis', 'Travis Scott Featuring SZA & Future', '77', '26', '10', 'All-American Bitch', 'Olivia Rodrigo', '56', '13', '4', 'Oh U Went', 'Young Thug Featuring Drake', '85', '19', '15', 'Standing Room Only', 'Tim McGraw', '96', '61', '5', 'On My Mama', 'Victoria Monet', '99', '76', '3', 'Sabor Fresa', 'Fuerza Regida', '79', '26', '15', 'Johnny Dang', 'That Mexican OT, Paul Wall & DRODi', '87', '65', '12', 'Tulum', 'Peso Pluma & Grupo Frontera', '78', '43', '14', 'Stick Season', 'Noah Kahan', '-', '80', '1', \"Can't Have Mine\", 'Dylan Scott', '98', '81', '2', 'Boys Of Faith', 'Zach Bryan Featuring Bon Iver', '26', '26', '2', 'Shaq & Kobe', 'Rick Ross & Meek Mill', '-', '83', '1', 'Pretty Little Poison', 'Warren Zeiders', '-', '59', '6', 'Bipolar', 'Peso Pluma x Jasiel Nunez x Junior H', '89', '60', '4', 'The Grudge', 'Olivia Rodrigo', '64', '16', '4', 'HG4', 'Rod Wave', '71', '51', '3', 'In Your Love', 'Tyler Childers', '90', '43', '10', 'Stars Like Confetti', 'Dustin Lynch', '-', '89', '1', 'God Gave Me A Girl', 'Russell Dickerson', '-', '90', '1', 'Spotless', 'Zach Bryan Featuring The Lumineers', '80', '17', '6', 'The Secret Recipe', 'Lil Yachty & J. Cole', '-', '92', '1', 'Oklahoma Smoke Show', 'Zach Bryan', '-', '80', '9', 'Que Onda', 'Calle 24 x Chino Pacas x Fuerza Regida', '-', '61', '3', 'FE!N', 'Travis Scott Featuring Playboi Carti', '-', '5', '9', 'Long Journey', 'Rod Wave', '75', '39', '3', 'But I Got A Beer In My Hand', 'Luke Bryan', '-', '92', '3', 'Rubicon', 'Peso Pluma', '-', '63', '12', 'East Side Of Sorrow', 'Zach Bryan', '95', '18', '6', 'Where She Goes', 'Bad Bunny', '-', '8', '19']\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# Scrape Song name, Artist name, Last week rank, Peak rank, Weeks on board \n",
    "\n",
    "all2 = []\n",
    "\n",
    "for i in range(0, len(all1)):\n",
    "    for j in all1[i]:\n",
    "        all2.append(j)\n",
    "        \n",
    "print(all2)\n",
    "print(len(all2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f49f83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Paint The Town Red', 'Snooze', 'Cruel Summer', 'Fast Car', '3D', 'I Remember Everything', 'Last Night', 'Fukumean', 'Vampire', 'Calm Down', 'Dance The Night', 'Barbie World', \"Thinkin' Bout Me\", 'Greedy', 'Flowers', 'Religiously', 'Need A Favor', 'Slime You Out', 'Bad Idea Right?', 'Anti-Hero', 'Watermelon Moonshine', 'All My Life', 'Used To Be Young', 'Kill Bill', 'Better Place', 'Dial Drunk', 'What Was I Made For?', 'Good Good', 'What It Is (Block Boy)', 'Rich Men North Of Richmond', 'Karma', \"Creepin'\", 'Daylight', 'Agora Hills', 'I Know ?', 'Try That In A Small Town', 'Save Me', 'White Horse', 'Peaches & Eggplants', 'Meltdown', 'Great Gatsby', 'Qlona', 'Un Preview', 'Lady Gaga', 'Get Him Back!', 'Bongos', 'Hey Driver', 'Single Soon', 'My Love Mine All Mine', \"Boyz Don't Cry\", 'Lil Boo Thang', 'Turks & Caicos', \"Sarah's Place\", 'LaLa', \"Mamaw's House\", 'Strangers', 'Seven', 'Lose Control', 'Call Your Friends', 'Come See Me', 'Everything I Love', 'SkeeYee', 'Truck Bed', 'Mi Ex Tenia Razon', 'Tourniquet', 'Popular', 'Water', 'El Amor de Su Vida', 'Segun Quien', '500lbs', 'Deli', 'Telekinesis', 'All-American Bitch', 'Oh U Went', 'Standing Room Only', 'On My Mama', 'Sabor Fresa', 'Johnny Dang', 'Tulum', 'Stick Season', \"Can't Have Mine\", 'Boys Of Faith', 'Shaq & Kobe', 'Pretty Little Poison', 'Bipolar', 'The Grudge', 'HG4', 'In Your Love', 'Stars Like Confetti', 'God Gave Me A Girl', 'Spotless', 'The Secret Recipe', 'Oklahoma Smoke Show', 'Que Onda', 'FE!N', 'Long Journey', 'But I Got A Beer In My Hand', 'Rubicon', 'East Side Of Sorrow', 'Where She Goes']\n",
      "100\n",
      "['Doja Cat', 'SZA', 'Taylor Swift', 'Luke Combs', 'Jung Kook & Jack Harlow', 'Zach Bryan Featuring Kacey Musgraves', 'Morgan Wallen', 'Gunna', 'Olivia Rodrigo', 'Rema & Selena Gomez', 'Dua Lipa', 'Nicki Minaj & Ice Spice With Aqua', 'Morgan Wallen', 'Tate McRae', 'Miley Cyrus', 'Bailey Zimmerman', 'Jelly Roll', 'Drake Featuring SZA', 'Olivia Rodrigo', 'Taylor Swift', 'Lainey Wilson', 'Lil Durk Featuring J. Cole', 'Miley Cyrus', 'SZA', '*NSYNC', 'Noah Kahan With Post Malone', 'Billie Eilish', 'Usher, Summer Walker & 21 Savage', 'Doechii Featuring Kodak Black', 'Oliver Anthony Music', 'Taylor Swift Featuring Ice Spice', 'Metro Boomin, The Weeknd & 21 Savage', 'David Kushner', 'Doja Cat', 'Travis Scott', 'Jason Aldean', 'Jelly Roll With Lainey Wilson', 'Chris Stapleton', 'Young Nudy Featuring 21 Savage', 'Travis Scott Featuring Drake', 'Rod Wave', 'Karol G & Peso Pluma', 'Bad Bunny', 'Peso Pluma, Gabito Ballesteros & Junior H', 'Olivia Rodrigo', 'Cardi B & Megan Thee Stallion', 'Zach Bryan Featuring The War And Treaty', 'Selena Gomez', 'Mitski', 'Rod Wave', 'Paul Russell', 'Rod Wave Featuring 21 Savage', 'Zach Bryan Featuring Noah Kahan', 'Myke Towers', 'Thomas Rhett Featuring Morgan Wallen', 'Kenya Grace', 'Jung Kook Featuring Latto', 'Teddy Swims', 'Rod Wave', 'Rod Wave', 'Morgan Wallen', 'Sexyy Red', 'HARDY', 'Karol G', 'Zach Bryan', 'The Weeknd, Playboi Carti & Madonna', 'Tyla', 'Grupo Frontera & Grupo Firme', 'Maluma & Carin Leon', 'Lil Tecca', 'Ice Spice', 'Travis Scott Featuring SZA & Future', 'Olivia Rodrigo', 'Young Thug Featuring Drake', 'Tim McGraw', 'Victoria Monet', 'Fuerza Regida', 'That Mexican OT, Paul Wall & DRODi', 'Peso Pluma & Grupo Frontera', 'Noah Kahan', 'Dylan Scott', 'Zach Bryan Featuring Bon Iver', 'Rick Ross & Meek Mill', 'Warren Zeiders', 'Peso Pluma x Jasiel Nunez x Junior H', 'Olivia Rodrigo', 'Rod Wave', 'Tyler Childers', 'Dustin Lynch', 'Russell Dickerson', 'Zach Bryan Featuring The Lumineers', 'Lil Yachty & J. Cole', 'Zach Bryan', 'Calle 24 x Chino Pacas x Fuerza Regida', 'Travis Scott Featuring Playboi Carti', 'Rod Wave', 'Luke Bryan', 'Peso Pluma', 'Zach Bryan', 'Bad Bunny']\n",
      "100\n",
      "['9', '43', '22', '28', '1', '6', '36', '16', '14', '57', '19', '15', '31', '3', '38', '22', '27', '3', '8', '50', '15', '21', '6', '43', '1', '16', '12', '8', '22', '8', '30', '44', '25', '2', '10', '12', '16', '11', '18', '10', '3', '8', '2', '15', '4', '4', '6', '6', '2', '3', '3', '3', '2', '13', '1', '3', '12', '8', '7', '5', '32', '5', '16', '8', '6', '18', '1', '7', '2', '2', '11', '10', '4', '15', '5', '3', '15', '12', '14', '1', '2', '2', '1', '6', '4', '4', '3', '10', '1', '1', '6', '1', '9', '3', '9', '3', '3', '12', '6', '19']\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "Song_name = []\n",
    "Artist_name = []\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "Weeks_on_board = []\n",
    "\n",
    "for i in range(0, len(all2), 5):\n",
    "    Song_name.append(all2[i])\n",
    "print(Song_name)\n",
    "print(len(Song_name))\n",
    "\n",
    "for i in range(1, len(all2), 5):\n",
    "    Artist_name.append(all2[i])\n",
    "print(Artist_name)\n",
    "print(len(Artist_name))\n",
    "\n",
    "for i in range(2, len(all2), 5):\n",
    "    Last_week_rank.append(all2[i])\n",
    "    \n",
    "for i in range(3, len(all2), 5):\n",
    "    Peak_rank.append(all2[i])\n",
    "    \n",
    "for i in range(4, len(all2), 5):\n",
    "    Weeks_on_board.append(all2[i])\n",
    "print(Weeks_on_board)\n",
    "print(len(Weeks_on_board))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445bf6c2",
   "metadata": {},
   "source": [
    "## Q5 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "025d7a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snooze</td>\n",
       "      <td>SZA</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D</td>\n",
       "      <td>Jung Kook &amp; Jack Harlow</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Long Journey</td>\n",
       "      <td>Rod Wave</td>\n",
       "      <td>75</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>But I Got A Beer In My Hand</td>\n",
       "      <td>Luke Bryan</td>\n",
       "      <td>-</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rubicon</td>\n",
       "      <td>Peso Pluma</td>\n",
       "      <td>-</td>\n",
       "      <td>63</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>East Side Of Sorrow</td>\n",
       "      <td>Zach Bryan</td>\n",
       "      <td>95</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Where She Goes</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Song Name              Artist Name Last Week Rank  \\\n",
       "0            Paint The Town Red                 Doja Cat              1   \n",
       "1                        Snooze                      SZA              2   \n",
       "2                  Cruel Summer             Taylor Swift              4   \n",
       "3                      Fast Car               Luke Combs              3   \n",
       "4                            3D  Jung Kook & Jack Harlow              -   \n",
       "..                          ...                      ...            ...   \n",
       "95                 Long Journey                 Rod Wave             75   \n",
       "96  But I Got A Beer In My Hand               Luke Bryan              -   \n",
       "97                      Rubicon               Peso Pluma              -   \n",
       "98          East Side Of Sorrow               Zach Bryan             95   \n",
       "99               Where She Goes                Bad Bunny              -   \n",
       "\n",
       "   Peak Rank Weeks on Board  \n",
       "0          1              9  \n",
       "1          2             43  \n",
       "2          3             22  \n",
       "3          2             28  \n",
       "4          5              1  \n",
       "..       ...            ...  \n",
       "95        39              3  \n",
       "96        92              3  \n",
       "97        63             12  \n",
       "98        18              6  \n",
       "99         8             19  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Song Name' : Song_name,\n",
    "    'Artist Name':Artist_name,\n",
    "    'Last Week Rank':Last_week_rank,\n",
    "    'Peak Rank':Peak_rank,\n",
    "    'Weeks on Board':Weeks_on_board\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf449be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa1fc082",
   "metadata": {},
   "source": [
    "## Q6 Scrape the details of Highest selling novels. \n",
    "A) Book name \n",
    "B) Author name \n",
    "C) Volumes sold \n",
    "D) Publisher \n",
    "E) Genre \n",
    " Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3edb92f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb5a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbody = driver.find_element(By.XPATH, '/html/body/div/div[2]/div[2]/div/div[2]/div/table')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "data3 = []\n",
    "for tr in tbody.find_elements(By.XPATH, \"//tr\")[1:]:\n",
    "    r = [td.text.replace(\"\\n\", ' ') for td in tr.find_elements(By.XPATH, './/td')]\n",
    "    if(len(r) == 6):\n",
    "        Book_Name = r[1]\n",
    "        Author_Name = r[2]\n",
    "        Volumes_Sold = r[3]\n",
    "        Publisher  = r[4]\n",
    "        Genre = r[5]\n",
    "        data3.append([Book_Name, Author_Name, Volumes_Sold, Publisher, Genre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a8142c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Da Vinci Code,The', 'Brown, Dan', '5,094,805', 'Transworld', 'Crime, Thriller & Adventure'], ['Harry Potter and the Deathly Hallows', 'Rowling, J.K.', '4,475,152', 'Bloomsbury', \"Children's Fiction\"], [\"Harry Potter and the Philosopher's Stone\", 'Rowling, J.K.', '4,200,654', 'Bloomsbury', \"Children's Fiction\"], ['Harry Potter and the Order of the Phoenix', 'Rowling, J.K.', '4,179,479', 'Bloomsbury', \"Children's Fiction\"], ['Fifty Shades of Grey', 'James, E. L.', '3,758,936', 'Random House', 'Romance & Sagas'], ['Harry Potter and the Goblet of Fire', 'Rowling, J.K.', '3,583,215', 'Bloomsbury', \"Children's Fiction\"], ['Harry Potter and the Chamber of Secrets', 'Rowling, J.K.', '3,484,047', 'Bloomsbury', \"Children's Fiction\"], ['Harry Potter and the Prisoner of Azkaban', 'Rowling, J.K.', '3,377,906', 'Bloomsbury', \"Children's Fiction\"], ['Angels and Demons', 'Brown, Dan', '3,193,946', 'Transworld', 'Crime, Thriller & Adventure'], [\"Harry Potter and the Half-blood Prince:Children's Edition\", 'Rowling, J.K.', '2,950,264', 'Bloomsbury', \"Children's Fiction\"], ['Fifty Shades Darker', 'James, E. L.', '2,479,784', 'Random House', 'Romance & Sagas'], ['Twilight', 'Meyer, Stephenie', '2,315,405', 'Little, Brown Book', 'Young Adult Fiction'], ['Girl with the Dragon Tattoo,The:Millennium Trilogy', 'Larsson, Stieg', '2,233,570', 'Quercus', 'Crime, Thriller & Adventure'], ['Fifty Shades Freed', 'James, E. L.', '2,193,928', 'Random House', 'Romance & Sagas'], ['Lost Symbol,The', 'Brown, Dan', '2,183,031', 'Transworld', 'Crime, Thriller & Adventure'], ['New Moon', 'Meyer, Stephenie', '2,152,737', 'Little, Brown Book', 'Young Adult Fiction'], ['Deception Point', 'Brown, Dan', '2,062,145', 'Transworld', 'Crime, Thriller & Adventure'], ['Eclipse', 'Meyer, Stephenie', '2,052,876', 'Little, Brown Book', 'Young Adult Fiction'], ['Lovely Bones,The', 'Sebold, Alice', '2,005,598', 'Pan Macmillan', 'General & Literary Fiction'], ['Curious Incident of the Dog in the Night-time,The', 'Haddon, Mark', '1,979,552', 'Random House', 'General & Literary Fiction'], ['Digital Fortress', 'Brown, Dan', '1,928,900', 'Transworld', 'Crime, Thriller & Adventure'], ['Short History of Nearly Everything,A', 'Bryson, Bill', '1,852,919', 'Transworld', 'Popular Science'], ['Girl Who Played with Fire,The:Millennium Trilogy', 'Larsson, Stieg', '1,814,784', 'Quercus', 'Crime, Thriller & Adventure'], ['Breaking Dawn', 'Meyer, Stephenie', '1,787,118', 'Little, Brown Book', 'Young Adult Fiction'], ['Very Hungry Caterpillar,The:The Very Hungry Caterpillar', 'Carle, Eric', '1,783,535', 'Penguin', 'Picture Books'], ['Gruffalo,The', 'Donaldson, Julia', '1,781,269', 'Pan Macmillan', 'Picture Books'], [\"Jamie's 30-Minute Meals\", 'Oliver, Jamie', '1,743,266', 'Penguin', 'Food & Drink: General'], ['Kite Runner,The', 'Hosseini, Khaled', '1,629,119', 'Bloomsbury', 'General & Literary Fiction'], ['One Day', 'Nicholls, David', '1,616,068', 'Hodder & Stoughton', 'General & Literary Fiction'], ['Thousand Splendid Suns,A', 'Hosseini, Khaled', '1,583,992', 'Bloomsbury', 'General & Literary Fiction'], [\"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\", 'Larsson, Stieg', '1,555,135', 'Quercus', 'Crime, Thriller & Adventure'], [\"Time Traveler's Wife,The\", 'Niffenegger, Audrey', '1,546,886', 'Random House', 'General & Literary Fiction'], ['Atonement', 'McEwan, Ian', '1,539,428', 'Random House', 'General & Literary Fiction'], [\"Bridget Jones's Diary:A Novel\", 'Fielding, Helen', '1,508,205', 'Pan Macmillan', 'General & Literary Fiction'], ['World According to Clarkson,The', 'Clarkson, Jeremy', '1,489,403', 'Penguin', 'Humour: Collections & General'], [\"Captain Corelli's Mandolin\", 'Bernieres, Louis de', '1,352,318', 'Random House', 'General & Literary Fiction'], ['Sound of Laughter,The', 'Kay, Peter', '1,310,207', 'Random House', 'Autobiography: General'], ['Life of Pi', 'Martel, Yann', '1,310,176', 'Canongate', 'General & Literary Fiction'], ['Billy Connolly', 'Stephenson, Pamela', '1,231,957', 'HarperCollins', 'Biography: The Arts'], ['Child Called It,A', 'Pelzer, Dave', '1,217,712', 'Orion', 'Autobiography: General'], [\"Gruffalo's Child,The\", 'Donaldson, Julia', '1,208,711', 'Pan Macmillan', 'Picture Books'], [\"Angela's Ashes:A Memoir of a Childhood\", 'McCourt, Frank', '1,204,058', 'HarperCollins', 'Autobiography: General'], ['Birdsong', 'Faulks, Sebastian', '1,184,967', 'Random House', 'General & Literary Fiction'], ['Northern Lights:His Dark Materials S.', 'Pullman, Philip', '1,181,503', 'Scholastic Ltd.', 'Young Adult Fiction'], ['Labyrinth', 'Mosse, Kate', '1,181,093', 'Orion', 'General & Literary Fiction'], ['Harry Potter and the Half-blood Prince', 'Rowling, J.K.', '1,153,181', 'Bloomsbury', 'Science Fiction & Fantasy'], ['Help,The', 'Stockett, Kathryn', '1,132,336', 'Penguin', 'General & Literary Fiction'], ['Man and Boy', 'Parsons, Tony', '1,130,802', 'HarperCollins', 'General & Literary Fiction'], ['Memoirs of a Geisha', 'Golden, Arthur', '1,126,337', 'Random House', 'General & Literary Fiction'], [\"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\", 'McCall Smith, Alexander', '1,115,549', 'Little, Brown Book', 'Crime, Thriller & Adventure'], ['Island,The', 'Hislop, Victoria', '1,108,328', 'Headline', 'General & Literary Fiction'], ['PS, I Love You', 'Ahern, Cecelia', '1,107,379', 'HarperCollins', 'General & Literary Fiction'], ['You are What You Eat:The Plan That Will Change Your Life', 'McKeith, Gillian', '1,104,403', 'Penguin', 'Fitness & Diet'], ['Shadow of the Wind,The', 'Zafon, Carlos Ruiz', '1,092,349', 'Orion', 'General & Literary Fiction'], ['Tales of Beedle the Bard,The', 'Rowling, J.K.', '1,090,847', 'Bloomsbury', \"Children's Fiction\"], ['Broker,The', 'Grisham, John', '1,087,262', 'Random House', 'Crime, Thriller & Adventure'], [\"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\", 'Atkins, Robert C.', '1,054,196', 'Random House', 'Fitness & Diet'], ['Subtle Knife,The:His Dark Materials S.', 'Pullman, Philip', '1,037,160', 'Scholastic Ltd.', 'Young Adult Fiction'], ['Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation', 'Truss, Lynne', '1,023,688', 'Profile Books Group', 'Usage & Writing Guides'], [\"Delia's How to Cook:(Bk.1)\", 'Smith, Delia', '1,015,956', 'Random House', 'Food & Drink: General'], ['Chocolat', 'Harris, Joanne', '1,009,873', 'Transworld', 'General & Literary Fiction'], ['Boy in the Striped Pyjamas,The', 'Boyne, John', '1,004,414', 'Random House Childrens Books G', 'Young Adult Fiction'], [\"My Sister's Keeper\", 'Picoult, Jodi', '1,003,780', 'Hodder & Stoughton', 'General & Literary Fiction'], ['Amber Spyglass,The:His Dark Materials S.', 'Pullman, Philip', '1,002,314', 'Scholastic Ltd.', 'Young Adult Fiction'], ['To Kill a Mockingbird', 'Lee, Harper', '998,213', 'Random House', 'General & Literary Fiction'], ['Men are from Mars, Women are from Venus:A Practical Guide for Improvin', 'Gray, John', '992,846', 'HarperCollins', 'Popular Culture & Media: General Interest'], ['Dear Fatty', 'French, Dawn', '986,753', 'Random House', 'Autobiography: The Arts'], ['Short History of Tractors in Ukrainian,A', 'Lewycka, Marina', '986,115', 'Penguin', 'General & Literary Fiction'], ['Hannibal', 'Harris, Thomas', '970,509', 'Random House', 'Crime, Thriller & Adventure'], ['Lord of the Rings,The', 'Tolkien, J. R. R.', '967,466', 'HarperCollins', 'Science Fiction & Fantasy'], ['Stupid White Men:...and Other Sorry Excuses for the State of the Natio', 'Moore, Michael', '963,353', 'Penguin', 'Current Affairs & Issues'], ['Interpretation of Murder,The', 'Rubenfeld, Jed', '962,515', 'Headline', 'Crime, Thriller & Adventure'], ['Sharon Osbourne Extreme:My Autobiography', 'Osbourne, Sharon', '959,496', 'Little, Brown Book', 'Autobiography: The Arts'], ['Alchemist,The:A Fable About Following Your Dream', 'Coelho, Paulo', '956,114', 'HarperCollins', 'General & Literary Fiction'], [\"At My Mother's Knee ...:and Other Low Joints\", \"O'Grady, Paul\", '945,640', 'Transworld', 'Autobiography: The Arts'], ['Notes from a Small Island', 'Bryson, Bill', '931,312', 'Transworld', 'Travel Writing'], ['Return of the Naked Chef,The', 'Oliver, Jamie', '925,425', 'Penguin', 'Food & Drink: General'], ['Bridget Jones: The Edge of Reason', 'Fielding, Helen', '924,695', 'Pan Macmillan', 'General & Literary Fiction'], [\"Jamie's Italy\", 'Oliver, Jamie', '906,968', 'Penguin', 'National & Regional Cuisine'], ['I Can Make You Thin', 'McKenna, Paul', '905,086', 'Transworld', 'Fitness & Diet'], ['Down Under', 'Bryson, Bill', '890,847', 'Transworld', 'Travel Writing'], ['Summons,The', 'Grisham, John', '869,671', 'Random House', 'Crime, Thriller & Adventure'], ['Small Island', 'Levy, Andrea', '869,659', 'Headline', 'General & Literary Fiction'], ['Nigella Express', 'Lawson, Nigella', '862,602', 'Random House', 'Food & Drink: General'], ['Brick Lane', 'Ali, Monica', '856,540', 'Transworld', 'General & Literary Fiction'], [\"Memory Keeper's Daughter,The\", 'Edwards, Kim', '845,858', 'Penguin', 'General & Literary Fiction'], ['Room on the Broom', 'Donaldson, Julia', '842,535', 'Pan Macmillan', 'Picture Books'], ['About a Boy', 'Hornby, Nick', '828,215', 'Penguin', 'General & Literary Fiction'], ['My Booky Wook', 'Brand, Russell', '820,563', 'Hodder & Stoughton', 'Autobiography: The Arts'], ['God Delusion,The', 'Dawkins, Richard', '816,907', 'Transworld', 'Popular Science'], ['\"Beano\" Annual,The', '0', '816,585', 'D.C. Thomson', \"Children's Annuals\"], ['White Teeth', 'Smith, Zadie', '815,586', 'Penguin', 'General & Literary Fiction'], ['House at Riverton,The', 'Morton, Kate', '814,370', 'Pan Macmillan', 'General & Literary Fiction'], ['Book Thief,The', 'Zusak, Markus', '809,641', 'Transworld', 'General & Literary Fiction'], ['Nights of Rain and Stars', 'Binchy, Maeve', '808,900', 'Orion', 'General & Literary Fiction'], ['Ghost,The', 'Harris, Robert', '807,311', 'Random House', 'General & Literary Fiction'], ['Happy Days with the Naked Chef', 'Oliver, Jamie', '794,201', 'Penguin', 'Food & Drink: General'], ['Hunger Games,The:Hunger Games Trilogy', 'Collins, Suzanne', '792,187', 'Scholastic Ltd.', 'Young Adult Fiction'], [\"Lost Boy,The:A Foster Child's Search for the Love of a Family\", 'Pelzer, Dave', '791,507', 'Orion', 'Biography: General'], [\"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\", 'Oliver, Jamie', '791,095', 'Penguin', 'Food & Drink: General']]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(data3)\n",
    "print(len(data3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04d1467",
   "metadata": {},
   "source": [
    "## Q6 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e16aa5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Book name       Author name  \\\n",
      "0                                   Da Vinci Code,The        Brown, Dan   \n",
      "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
      "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
      "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
      "4                                Fifty Shades of Grey      James, E. L.   \n",
      "..                                                ...               ...   \n",
      "95                                          Ghost,The    Harris, Robert   \n",
      "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
      "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
      "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
      "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
      "\n",
      "   Volumes sold        Publisher                        Genre  \n",
      "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
      "1     4,475,152       Bloomsbury           Children's Fiction  \n",
      "2     4,200,654       Bloomsbury           Children's Fiction  \n",
      "3     4,179,479       Bloomsbury           Children's Fiction  \n",
      "4     3,758,936     Random House              Romance & Sagas  \n",
      "..          ...              ...                          ...  \n",
      "95      807,311     Random House   General & Literary Fiction  \n",
      "96      794,201          Penguin        Food & Drink: General  \n",
      "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
      "98      791,507            Orion           Biography: General  \n",
      "99      791,095          Penguin        Food & Drink: General  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Create a DataFrame\n",
    "df = pd.DataFrame(data3, columns=['Book name', 'Author name', 'Volumes sold', 'Publisher', 'Genre'])\n",
    "\n",
    "#Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b952055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf18e971",
   "metadata": {},
   "source": [
    "## Q7 Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/ You have \n",
    "to find the following details: \n",
    "A) Name \n",
    "B) Year span \n",
    "C) Genre \n",
    "D) Run time \n",
    "E) Ratings \n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c256863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8837d1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1. Game of Thrones ', '2011–2019)'], ['2. Stranger Things ', '2016–2025)'], ['3. The Walking Dead ', '2010–2022)'], ['4. 13 Reasons Why ', '2017–2020)'], ['5. The 100 ', '2014–2020)'], ['6. Orange Is the New Black ', '2013–2019)'], ['7. Riverdale ', '2017–2023)'], [\"8. Grey's Anatomy \", '2005– )'], ['9. The Flash ', '2014–2023)'], ['10. Arrow ', '2012–2020)'], ['11. Money Heist ', '2017–2021)'], ['12. The Big Bang Theory ', '2007–2019)'], ['13. Black Mirror ', '2011– )'], ['14. Sherlock ', '2010–2017)'], ['15. Vikings ', '2013–2020)'], ['16. Pretty Little Liars ', '2010–2017)'], ['17. The Vampire Diaries ', '2009–2017)'], ['18. American Horror Story ', '2011– )'], ['19. Breaking Bad ', '2008–2013)'], ['20. Lucifer ', '2016–2021)'], ['21. Supernatural ', '2005–2020)'], ['22. Prison Break ', '2005–2017)'], ['23. How to Get Away with Murder ', '2014–2020)'], ['24. Teen Wolf ', '2011–2017)'], ['25. The Simpsons ', '1989– )'], ['26. Once Upon a Time ', '2011–2018)'], ['27. Narcos ', 'I) ', '2015–2017)'], ['28. Daredevil ', '2015–2018)'], ['29. Friends ', '1994–2004)'], ['30. How I Met Your Mother ', '2005–2014)'], ['31. Suits ', '2011–2019)'], ['32. Mr. Robot ', '2015–2019)'], ['33. The Originals ', '2013–2018)'], ['34. Supergirl ', '2015–2021)'], ['35. Gossip Girl ', '2007–2012)'], ['36. Sense8 ', '2015–2018)'], ['37. Gotham ', '2014–2019)'], ['38. Westworld ', '2016–2022)'], ['39. Jessica Jones ', '2015–2019)'], ['40. Modern Family ', '2009–2020)'], ['41. Rick and Morty ', '2013– )'], ['42. Shadowhunters ', '2016–2019)'], ['43. The End of the F***ing World ', '2017–2019)'], ['44. House of Cards ', '2013–2018)'], ['45. Dark ', '2017–2020)'], ['46. Elite ', '2018– )'], ['47. Sex Education ', '2019–2023)'], ['48. Shameless ', '2011–2021)'], ['49. New Girl ', '2011–2018)'], ['50. Agents of S.H.I.E.L.D. ', '2013–2020)'], ['51. You ', '2018–2024)'], ['52. Dexter ', '2006–2013)'], ['53. Fear the Walking Dead ', '2015–2023)'], ['54. Family Guy ', '1999– )'], ['55. The Blacklist ', '2013–2023)'], ['56. Lost ', '2004–2010)'], ['57. Peaky Blinders ', '2013–2022)'], ['58. House ', '2004–2012)'], ['59. Quantico ', '2015–2018)'], ['60. Orphan Black ', '2013–2017)'], ['61. Homeland ', '2011–2020)'], ['62. Blindspot ', '2015–2020)'], [\"63. DC's Legends of Tomorrow \", '2016–2022)'], [\"64. The Handmaid's Tale \", '2017– )'], ['65. Chilling Adventures of Sabrina ', '2018–2020)'], ['66. The Good Doctor ', '2017– )'], ['67. Jane the Virgin ', '2014–2019)'], ['68. Glee ', '2009–2015)'], ['69. South Park ', '1997– )'], ['70. Brooklyn Nine-Nine ', '2013–2021)'], ['71. Under the Dome ', '2013–2015)'], ['72. The Umbrella Academy ', '2019–2024)'], ['73. True Detective ', '2014– )'], ['74. The OA ', '2016–2019)'], ['75. Desperate Housewives ', '2004–2012)'], ['76. Better Call Saul ', '2015–2022)'], ['77. Bates Motel ', '2013–2017)'], ['78. The Punisher ', '2017–2019)'], ['79. Atypical ', '2017–2021)'], ['80. Dynasty ', '2017–2022)'], ['81. This Is Us ', '2016–2022)'], ['82. The Good Place ', '2016–2020)'], ['83. Iron Fist ', '2017–2018)'], ['84. The Rain ', '2018–2020)'], ['85. Mindhunter ', '2017–2019)'], ['86. Revenge ', '2011–2015)'], ['87. Luke Cage ', '2016–2018)'], ['88. Scandal ', '2012–2018)'], ['89. The Defenders ', '2017)'], ['90. Big Little Lies ', '2017–2019)'], ['91. Insatiable ', '2018–2019)'], ['92. The Mentalist ', '2008–2015)'], ['93. The Crown ', '2016–2023)'], ['94. Chernobyl ', '2019)'], ['95. iZombie ', '2015–2019)'], ['96. Reign ', '2013–2017)'], ['97. A Series of Unfortunate Events ', '2017–2019)'], ['98. Criminal Minds ', '2005– )'], ['99. Scream: The TV Series ', '2015–2019)'], ['100. The Haunting of Hill House ', '2018)']]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#Scrape Name,Year span,Genre,Run time,Ratings,Votes\n",
    "all_heading = []\n",
    "all_heading_elements = driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]')\n",
    "    \n",
    "for i in all_heading_elements:\n",
    "    all_heading.append(i.text.split('('))\n",
    "    \n",
    "print(all_heading)\n",
    "print(len(all_heading))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e29e145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. Game of Thrones ', '2011–2019)', '2. Stranger Things ', '2016–2025)', '3. The Walking Dead ', '2010–2022)', '4. 13 Reasons Why ', '2017–2020)', '5. The 100 ', '2014–2020)', '6. Orange Is the New Black ', '2013–2019)', '7. Riverdale ', '2017–2023)', \"8. Grey's Anatomy \", '2005– )', '9. The Flash ', '2014–2023)', '10. Arrow ', '2012–2020)', '11. Money Heist ', '2017–2021)', '12. The Big Bang Theory ', '2007–2019)', '13. Black Mirror ', '2011– )', '14. Sherlock ', '2010–2017)', '15. Vikings ', '2013–2020)', '16. Pretty Little Liars ', '2010–2017)', '17. The Vampire Diaries ', '2009–2017)', '18. American Horror Story ', '2011– )', '19. Breaking Bad ', '2008–2013)', '20. Lucifer ', '2016–2021)', '21. Supernatural ', '2005–2020)', '22. Prison Break ', '2005–2017)', '23. How to Get Away with Murder ', '2014–2020)', '24. Teen Wolf ', '2011–2017)', '25. The Simpsons ', '1989– )', '26. Once Upon a Time ', '2011–2018)', '27. Narcos ', '2015–2017)', '28. Daredevil ', '2015–2018)', '29. Friends ', '1994–2004)', '30. How I Met Your Mother ', '2005–2014)', '31. Suits ', '2011–2019)', '32. Mr. Robot ', '2015–2019)', '33. The Originals ', '2013–2018)', '34. Supergirl ', '2015–2021)', '35. Gossip Girl ', '2007–2012)', '36. Sense8 ', '2015–2018)', '37. Gotham ', '2014–2019)', '38. Westworld ', '2016–2022)', '39. Jessica Jones ', '2015–2019)', '40. Modern Family ', '2009–2020)', '41. Rick and Morty ', '2013– )', '42. Shadowhunters ', '2016–2019)', '43. The End of the F***ing World ', '2017–2019)', '44. House of Cards ', '2013–2018)', '45. Dark ', '2017–2020)', '46. Elite ', '2018– )', '47. Sex Education ', '2019–2023)', '48. Shameless ', '2011–2021)', '49. New Girl ', '2011–2018)', '50. Agents of S.H.I.E.L.D. ', '2013–2020)', '51. You ', '2018–2024)', '52. Dexter ', '2006–2013)', '53. Fear the Walking Dead ', '2015–2023)', '54. Family Guy ', '1999– )', '55. The Blacklist ', '2013–2023)', '56. Lost ', '2004–2010)', '57. Peaky Blinders ', '2013–2022)', '58. House ', '2004–2012)', '59. Quantico ', '2015–2018)', '60. Orphan Black ', '2013–2017)', '61. Homeland ', '2011–2020)', '62. Blindspot ', '2015–2020)', \"63. DC's Legends of Tomorrow \", '2016–2022)', \"64. The Handmaid's Tale \", '2017– )', '65. Chilling Adventures of Sabrina ', '2018–2020)', '66. The Good Doctor ', '2017– )', '67. Jane the Virgin ', '2014–2019)', '68. Glee ', '2009–2015)', '69. South Park ', '1997– )', '70. Brooklyn Nine-Nine ', '2013–2021)', '71. Under the Dome ', '2013–2015)', '72. The Umbrella Academy ', '2019–2024)', '73. True Detective ', '2014– )', '74. The OA ', '2016–2019)', '75. Desperate Housewives ', '2004–2012)', '76. Better Call Saul ', '2015–2022)', '77. Bates Motel ', '2013–2017)', '78. The Punisher ', '2017–2019)', '79. Atypical ', '2017–2021)', '80. Dynasty ', '2017–2022)', '81. This Is Us ', '2016–2022)', '82. The Good Place ', '2016–2020)', '83. Iron Fist ', '2017–2018)', '84. The Rain ', '2018–2020)', '85. Mindhunter ', '2017–2019)', '86. Revenge ', '2011–2015)', '87. Luke Cage ', '2016–2018)', '88. Scandal ', '2012–2018)', '89. The Defenders ', '2017)', '90. Big Little Lies ', '2017–2019)', '91. Insatiable ', '2018–2019)', '92. The Mentalist ', '2008–2015)', '93. The Crown ', '2016–2023)', '94. Chernobyl ', '2019)', '95. iZombie ', '2015–2019)', '96. Reign ', '2013–2017)', '97. A Series of Unfortunate Events ', '2017–2019)', '98. Criminal Minds ', '2005– )', '99. Scream: The TV Series ', '2015–2019)', '100. The Haunting of Hill House ', '2018)']\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "#Scrape Name,Year span,Genre,Run time,Ratings,Votes\n",
    "\n",
    "general = []\n",
    "\n",
    "for i in range(0, len(all_heading)):\n",
    "    for j in all_heading[i]:\n",
    "        if (len(all_heading[i]) == 3):\n",
    "            all_heading[i].pop(1)\n",
    "        general.append(j)\n",
    "                \n",
    "print(general)\n",
    "print(len(general))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fac1868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011–2019\n"
     ]
    }
   ],
   "source": [
    "j = '2011–2019)'\n",
    "out = re.sub(r\"\\)\", '', j)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d81aa343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Game of Thrones ', ' Stranger Things ', ' The Walking Dead ', ' 13 Reasons Why ', ' The 100 ', ' Orange Is the New Black ', ' Riverdale ', \" Grey's Anatomy \", ' The Flash ', ' Arrow ', ' Money Heist ', ' The Big Bang Theory ', ' Black Mirror ', ' Sherlock ', ' Vikings ', ' Pretty Little Liars ', ' The Vampire Diaries ', ' American Horror Story ', ' Breaking Bad ', ' Lucifer ', ' Supernatural ', ' Prison Break ', ' How to Get Away with Murder ', ' Teen Wolf ', ' The Simpsons ', ' Once Upon a Time ', ' Narcos ', ' Daredevil ', ' Friends ', ' How I Met Your Mother ', ' Suits ', ' Mr. Robot ', ' The Originals ', ' Supergirl ', ' Gossip Girl ', ' Sense8 ', ' Gotham ', ' Westworld ', ' Jessica Jones ', ' Modern Family ', ' Rick and Morty ', ' Shadowhunters ', ' The End of the F***ing World ', ' House of Cards ', ' Dark ', ' Elite ', ' Sex Education ', ' Shameless ', ' New Girl ', ' Agents of S.H.I.E.L.D. ', ' You ', ' Dexter ', ' Fear the Walking Dead ', ' Family Guy ', ' The Blacklist ', ' Lost ', ' Peaky Blinders ', ' House ', ' Quantico ', ' Orphan Black ', ' Homeland ', ' Blindspot ', \" DC's Legends of Tomorrow \", \" The Handmaid's Tale \", ' Chilling Adventures of Sabrina ', ' The Good Doctor ', ' Jane the Virgin ', ' Glee ', ' South Park ', ' Brooklyn Nine-Nine ', ' Under the Dome ', ' The Umbrella Academy ', ' True Detective ', ' The OA ', ' Desperate Housewives ', ' Better Call Saul ', ' Bates Motel ', ' The Punisher ', ' Atypical ', ' Dynasty ', ' This Is Us ', ' The Good Place ', ' Iron Fist ', ' The Rain ', ' Mindhunter ', ' Revenge ', ' Luke Cage ', ' Scandal ', ' The Defenders ', ' Big Little Lies ', ' Insatiable ', ' The Mentalist ', ' The Crown ', ' Chernobyl ', ' iZombie ', ' Reign ', ' A Series of Unfortunate Events ', ' Criminal Minds ', ' Scream: The TV Series ', ' The Haunting of Hill House ']\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#Scrape Name,Year span,Genre,Run time,Ratings,Votes\n",
    "\n",
    "Name = []\n",
    "for i in range(0, len(general), 2):\n",
    "    out = re.sub(r\"^\\d+\\.\", '', general[i])\n",
    "    Name.append(out)\n",
    "    \n",
    "print(Name)\n",
    "print(len(Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a68754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2011–2019', '2016–2025', '2010–2022', '2017–2020', '2014–2020', '2013–2019', '2017–2023', '2005– ', '2014–2023', '2012–2020', '2017–2021', '2007–2019', '2011– ', '2010–2017', '2013–2020', '2010–2017', '2009–2017', '2011– ', '2008–2013', '2016–2021', '2005–2020', '2005–2017', '2014–2020', '2011–2017', '1989– ', '2011–2018', '2015–2017', '2015–2018', '1994–2004', '2005–2014', '2011–2019', '2015–2019', '2013–2018', '2015–2021', '2007–2012', '2015–2018', '2014–2019', '2016–2022', '2015–2019', '2009–2020', '2013– ', '2016–2019', '2017–2019', '2013–2018', '2017–2020', '2018– ', '2019–2023', '2011–2021', '2011–2018', '2013–2020', '2018–2024', '2006–2013', '2015–2023', '1999– ', '2013–2023', '2004–2010', '2013–2022', '2004–2012', '2015–2018', '2013–2017', '2011–2020', '2015–2020', '2016–2022', '2017– ', '2018–2020', '2017– ', '2014–2019', '2009–2015', '1997– ', '2013–2021', '2013–2015', '2019–2024', '2014– ', '2016–2019', '2004–2012', '2015–2022', '2013–2017', '2017–2019', '2017–2021', '2017–2022', '2016–2022', '2016–2020', '2017–2018', '2018–2020', '2017–2019', '2011–2015', '2016–2018', '2012–2018', '2017', '2017–2019', '2018–2019', '2008–2015', '2016–2023', '2019', '2015–2019', '2013–2017', '2017–2019', '2005– ', '2015–2019', '2018']\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#Scrape Name,Year span,Genre,Run time,Ratings,Votes\n",
    "\n",
    "Year_Span = []\n",
    "for i in range(1, len(general), 2):\n",
    "    out = re.sub(r\"\\)\", '', general[i])\n",
    "    Year_Span.append(out)\n",
    "    \n",
    "print(Year_Span)\n",
    "print(len(Year_Span))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9b830e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Action, Adventure, Drama', 'Drama, Fantasy, Horror', 'Drama, Horror, Thriller', 'Drama, Mystery, Thriller', 'Drama, Mystery, Sci-Fi', 'Comedy, Crime, Drama', 'Crime, Drama, Mystery', 'Drama, Romance', 'Action, Adventure, Drama', 'Action, Adventure, Crime', 'Action, Crime, Drama', 'Comedy, Romance', 'Drama, Mystery, Sci-Fi', 'Crime, Drama, Mystery', 'Action, Adventure, Drama', 'Drama, Mystery, Romance', 'Drama, Fantasy, Horror', 'Drama, Horror, Sci-Fi', 'Crime, Drama, Thriller', 'Crime, Drama, Fantasy', 'Drama, Fantasy, Horror', 'Action, Crime, Drama', 'Crime, Drama, Mystery', 'Action, Drama, Fantasy', 'Animation, Comedy', 'Adventure, Fantasy, Romance', 'Biography, Crime, Drama', 'Action, Crime, Drama', 'Comedy, Romance', 'Comedy, Drama, Romance', 'Comedy, Drama', 'Crime, Drama, Thriller', 'Drama, Fantasy, Horror', 'Action, Adventure, Drama', 'Drama, Romance', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Comedy, Drama, Romance', 'Animation, Adventure, Comedy', 'Action, Drama, Fantasy', 'Adventure, Comedy, Crime', 'Drama', 'Crime, Drama, Mystery', 'Crime, Drama, Thriller', 'Comedy, Drama', 'Comedy, Drama', 'Comedy, Romance', 'Action, Adventure, Drama', 'Crime, Drama, Romance', 'Crime, Drama, Mystery', 'Drama, Horror, Sci-Fi', 'Animation, Comedy', 'Crime, Drama, Mystery', 'Adventure, Drama, Fantasy', 'Crime, Drama', 'Drama, Mystery', 'Crime, Drama, Mystery', 'Drama, Sci-Fi, Thriller', 'Crime, Drama, Mystery', 'Action, Crime, Drama', 'Action, Adventure, Drama', 'Drama, Sci-Fi, Thriller', 'Drama, Fantasy, Horror', 'Drama', 'Comedy', 'Comedy, Drama, Music', 'Animation, Comedy', 'Comedy, Crime', 'Drama, Mystery, Sci-Fi', 'Action, Adventure, Comedy', 'Crime, Drama, Mystery', 'Drama, Fantasy, Mystery', 'Comedy, Drama, Mystery', 'Crime, Drama', 'Drama, Horror, Mystery', 'Action, Crime, Drama', 'Comedy, Drama', 'Drama', 'Comedy, Drama, Romance', 'Comedy, Drama, Fantasy', 'Action, Adventure, Crime', 'Drama, Sci-Fi, Thriller', 'Crime, Drama, Mystery', 'Drama, Mystery, Thriller', 'Action, Crime, Drama', 'Drama, Thriller', 'Action, Adventure, Crime', 'Crime, Drama, Mystery', 'Comedy, Drama, Thriller', 'Crime, Drama, Mystery', 'Biography, Drama, History', 'Drama, History, Thriller', 'Comedy, Crime, Drama', 'Drama', 'Adventure, Comedy, Drama', 'Crime, Drama, Mystery', 'Comedy, Crime, Drama', 'Drama, Horror, Mystery']\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#Scrape Name,Year span,Genre,Run time,Ratings,Votes\n",
    "\n",
    "Genre = []\n",
    "genre_elements = driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "\n",
    "for i in genre_elements:\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "print(Genre)\n",
    "print(len(Genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ae370bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['57 min', '51 min', '44 min', '60 min', '43 min', '59 min', '45 min', '41 min', '43 min', '42 min', '70 min', '22 min', '60 min', '88 min', '44 min', '44 min', '43 min', '60 min', '49 min', '42 min', '44 min', '44 min', '43 min', '41 min', '22 min', '60 min', '49 min', '54 min', '22 min', '22 min', '44 min', '49 min', '45 min', '43 min', '42 min', '60 min', '42 min', '62 min', '56 min', '22 min', '23 min', '42 min', '25 min', '51 min', '60 min', '60 min', '45 min', '46 min', '22 min', '45 min', '45 min', '53 min', '44 min', '22 min', '43 min', '44 min', '60 min', '44 min', '42 min', '44 min', '55 min', '42 min', '42 min', '60 min', '60 min', '41 min', '60 min', '44 min', '22 min', '22 min', '43 min', '60 min', '55 min', '60 min', '45 min', '46 min', '45 min', '53 min', '30 min', '42 min', '45 min', '22 min', '55 min', '45 min', '60 min', '44 min', '55 min', '43 min', '50 min', '60 min', '45 min', '43 min', '58 min', '330 min', '42 min', '42 min', '50 min', '42 min', '45 min', '572 min']\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#Scrape Name,Year span,Genre,Run time,Ratings,Votes\n",
    "\n",
    "Run_Time = []\n",
    "run_time_elements = driver.find_elements(By.XPATH, '//span[@class=\"runtime\"]')\n",
    "\n",
    "for i in run_time_elements:\n",
    "    Run_Time.append(i.text)\n",
    "    \n",
    "print(Run_Time)\n",
    "print(len(Run_Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a5fb9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9.2', '8.7', '8.1', '7.5', '7.6', '8', '6.5', '7.6', '7.5', '7.5', '8.2', '8.2', '8.7', '9.1', '8.5', '7.4', '7.7', '8', '9.5', '8.1', '8.4', '8.3', '8.1', '7.7', '8.7', '7.7', '8.8', '8.6', '8.9', '8.3', '8.4', '8.5', '8.3', '6.2', '7.5', '8.2', '7.8', '8.5', '7.9', '8.5', '9.1', '6.5', '8', '8.7', '8.7', '7.3', '8.3', '8.5', '7.8', '7.5', '7.7', '8.7', '6.8', '8.2', '8', '8.3', '8.8', '8.7', '6.7', '8.3', '8.3', '7.3', '6.8', '8.4', '7.4', '8', '7.9', '6.8', '8.7', '8.4', '6.5', '7.9', '8.9', '7.8', '7.6', '9', '8.1', '8.5', '8.2', '7.3', '8.7', '8.2', '6.4', '6.3', '8.6', '7.8', '7.3', '7.7', '7.2', '8.5', '6.5', '8.2', '8.6', '9.3', '7.8', '7.5', '7.8', '8.1', '7', '8.6']\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#Scrape Name,Year span,Genre,Run time,Ratings,Votes\n",
    "\n",
    "Ratings = []\n",
    "rating_elements = driver.find_elements(By.XPATH, \"//div[@class='ipl-rating-star small']\")\n",
    "\n",
    "for i in rating_elements:\n",
    "    Ratings.append(i.text)\n",
    "\n",
    "print(Ratings)\n",
    "print(len(Ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4549a8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2,212,548', '1,282,548', '1,049,804', '308,483', '267,455', '314,671', '152,218', '330,169', '363,718', '441,646', '510,633', '843,823', '614,883', '969,870', '563,788', '174,962', '339,798', '334,687', '2,049,188', '344,689', '468,909', '564,250', '161,835', '159,201', '425,558', '232,918', '454,043', '462,238', '1,049,257', '712,874', '454,132', '407,155', '143,946', '128,018', '186,710', '160,082', '237,501', '522,102', '222,516', '463,755', '570,964', '68,313', '210,697', '521,650', '422,955', '87,197', '328,239', '266,506', '238,942', '223,159', '285,874', '748,732', '138,740', '356,256', '272,255', '579,649', '611,658', '491,871', '62,991', '114,956', '354,384', '77,524', '108,652', '251,164', '104,374', '108,022', '56,608', '153,468', '395,789', '344,282', '110,511', '265,064', '611,223', '111,116', '135,926', '610,146', '114,191', '255,386', '99,570', '24,273', '152,898', '179,760', '136,908', '40,299', '317,628', '123,307', '136,985', '78,161', '113,786', '216,389', '31,456', '195,017', '235,114', '824,966', '72,377', '52,937', '65,009', '211,822', '44,085', '269,154']\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#Scrape Name,Year span,Genre,Run time,Ratings,Votes\n",
    "\n",
    "Votes = []\n",
    "votes_elements = driver.find_elements(By.XPATH, \"//span[@name='nv']\")\n",
    "\n",
    "for i in votes_elements:\n",
    "    Votes.append(i.text)\n",
    "\n",
    "print(Votes)\n",
    "print(len(Votes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c59b507",
   "metadata": {},
   "source": [
    "## Q7 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63995c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>2011–2019</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,212,548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>2016–2025</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,282,548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>2010–2022</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,049,804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>2017–2020</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>308,483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>2014–2020</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>267,455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>2013–2017</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>2017–2019</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>65,009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>2005–</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>211,822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>2015–2019</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>44,085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>2018</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>269,154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Name  Year span                     Genre  \\\n",
       "0                   Game of Thrones   2011–2019  Action, Adventure, Drama   \n",
       "1                   Stranger Things   2016–2025    Drama, Fantasy, Horror   \n",
       "2                  The Walking Dead   2010–2022   Drama, Horror, Thriller   \n",
       "3                    13 Reasons Why   2017–2020  Drama, Mystery, Thriller   \n",
       "4                           The 100   2014–2020    Drama, Mystery, Sci-Fi   \n",
       "..                               ...        ...                       ...   \n",
       "95                            Reign   2013–2017                     Drama   \n",
       "96   A Series of Unfortunate Events   2017–2019  Adventure, Comedy, Drama   \n",
       "97                   Criminal Minds      2005–      Crime, Drama, Mystery   \n",
       "98            Scream: The TV Series   2015–2019      Comedy, Crime, Drama   \n",
       "99       The Haunting of Hill House        2018    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0    57 min     9.2  2,212,548  \n",
       "1    51 min     8.7  1,282,548  \n",
       "2    44 min     8.1  1,049,804  \n",
       "3    60 min     7.5    308,483  \n",
       "4    43 min     7.6    267,455  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     52,937  \n",
       "96   50 min     7.8     65,009  \n",
       "97   42 min     8.1    211,822  \n",
       "98   45 min       7     44,085  \n",
       "99  572 min     8.6    269,154  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Name' : Name,\n",
    "    'Year span':Year_Span,\n",
    "    'Genre':Genre,\n",
    "    'Run time':Run_Time,\n",
    "    'Ratings':Ratings,\n",
    "    'Votes':Votes\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c87fec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30de958a",
   "metadata": {},
   "source": [
    "## Q8 Details of Datasets from UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/ You have to find the following details: \n",
    "A) Dataset name \n",
    "B) Data type \n",
    "C) Task \n",
    "D) Attribute type \n",
    "E) No of instances \n",
    "F) No of attribute \n",
    "G) Year \n",
    " Note: - from the home page you have to go to the Show All Dataset page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f9bee1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()\n",
    "driver.get('https://archive.ics.uci.edu/')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7e78ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "button_view_datasets = driver.find_element(By.XPATH, \"/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]\")  \n",
    "button_view_datasets.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b3f2bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris', 'Heart Disease', 'Adult', 'Wine', 'Breast Cancer Wisconsin (Diagnostic)', 'Diabetes', 'Dry Bean Dataset', 'Car Evaluation', 'Rice (Cammeo and Osmancik)', 'Mushroom']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Scrape - Dataset name \n",
    "\n",
    "dataset_name = []\n",
    "dataset_name_elements = driver.find_elements(By.XPATH, \"//a[@class='link-hover link text-xl font-semibold']\")\n",
    "\n",
    "for i in dataset_name_elements:\n",
    "    dataset_name.append(i.text)\n",
    "\n",
    "print(dataset_name)\n",
    "print(len(dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35f2a71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Classification', 'Tabular', '150 Instances', '4 Features', 'Classification', 'Multivariate', '303 Instances', '13 Features', 'Classification', 'Multivariate', '48.84K Instances', '14 Features', 'Classification', 'Tabular', '178 Instances', '13 Features', 'Classification', 'Multivariate', '569 Instances', '30 Features', '', '', '', '20 Features', 'Classification', 'Multivariate', '13.61K Instances', '16 Features', 'Classification', 'Multivariate', '1.73K Instances', '6 Features', 'Classification', 'Multivariate', '3.81K Instances', '8 Features', 'Classification', 'Multivariate', '8.12K Instances', '22 Features']\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Scrape - Data type, Task, No of instances, No of attribute\n",
    "\n",
    "all_4 = []\n",
    "all_4_elements = driver.find_elements(By.XPATH, \"//span[@class='truncate']\")\n",
    "\n",
    "for i in all_4_elements:\n",
    "    if all_4_elements == '':\n",
    "        all_4.append(\"--\")\n",
    "    else:\n",
    "        all_4.append(i.text)\n",
    "\n",
    "print(all_4)\n",
    "print(len(all_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5003e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tabular', 'Multivariate', 'Multivariate', 'Tabular', 'Multivariate', '-', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Scrape - Data type\n",
    "Data_Type = []\n",
    "\n",
    "for i in range(1, len(all_4), 4):\n",
    "    if all_4[i] == '':\n",
    "        Data_Type.append(\"-\")\n",
    "    else:\n",
    "        Data_Type.append(all_4[i])\n",
    "    \n",
    "print(Data_Type)\n",
    "print(len(Data_Type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11a57f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Classification', 'Classification', 'Classification', 'Classification', 'Classification', '-', 'Classification', 'Classification', 'Classification', 'Classification']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Scrape - Task\n",
    "Task = []\n",
    "\n",
    "for i in range(0, len(all_4), 4):\n",
    "    if all_4[i] == '':\n",
    "        Task.append(\"-\")\n",
    "    else:\n",
    "        Task.append(all_4[i])\n",
    "    \n",
    "print(Task)\n",
    "print(len(Task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "04cb23f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['150', 'Instances'], ['303', 'Instances'], ['48.84K', 'Instances'], ['178', 'Instances'], ['569', 'Instances'], '-', ['13.61K', 'Instances'], ['1.73K', 'Instances'], ['3.81K', 'Instances'], ['8.12K', 'Instances']]\n",
      "10\n",
      "['150', '303', '48.84K', '178', '569', '-', '13.61K', '1.73K', '3.81K', '8.12K']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Scrape - No of instances\n",
    "No_of_instances_1 = []\n",
    "\n",
    "for i in range(2, len(all_4), 4):\n",
    "    if all_4[i] == '':\n",
    "        No_of_instances_1.append(\"-\")\n",
    "    else:\n",
    "        No_of_instances_1.append(all_4[i].split(' '))\n",
    "    \n",
    "print(No_of_instances_1)\n",
    "print(len(No_of_instances_1))\n",
    "\n",
    "\n",
    "No_of_instances = []\n",
    "\n",
    "for i in range(0, len(No_of_instances_1)):\n",
    "    for j in No_of_instances_1[i]:\n",
    "        \n",
    "        if No_of_instances_1[i].index(j) == 0:\n",
    "            No_of_instances.append(j)\n",
    "                \n",
    "print(No_of_instances)\n",
    "print(len(No_of_instances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "91584b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['4', 'Features'], ['13', 'Features'], ['14', 'Features'], ['13', 'Features'], ['30', 'Features'], ['20', 'Features'], ['16', 'Features'], ['6', 'Features'], ['8', 'Features'], ['22', 'Features']]\n",
      "10\n",
      "['4', '13', '14', '13', '30', '20', '16', '6', '8', '22']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Scrape - No of attribute\n",
    "No_of_attribute_1 = []\n",
    "\n",
    "for i in range(3, len(all_4), 4):\n",
    "    if all_4[i] == '':\n",
    "        No_of_attribute_1.append(\"-\")\n",
    "    else:\n",
    "        No_of_attribute_1.append(all_4[i].split(' '))\n",
    "    \n",
    "print(No_of_attribute_1)\n",
    "print(len(No_of_attribute_1))\n",
    "\n",
    "\n",
    "\n",
    "No_of_attribute = []\n",
    "\n",
    "for i in range(0, len(No_of_attribute_1)):\n",
    "    for j in No_of_attribute_1[i]:\n",
    "        \n",
    "        if No_of_attribute_1[i].index(j) == 0:\n",
    "            No_of_attribute.append(j)\n",
    "                \n",
    "print(No_of_attribute)\n",
    "print(len(No_of_attribute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "70db8602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://archive.ics.uci.edu/dataset/53/iris', 'https://archive.ics.uci.edu/dataset/45/heart+disease', 'https://archive.ics.uci.edu/dataset/2/adult', 'https://archive.ics.uci.edu/dataset/109/wine', 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic', 'https://archive.ics.uci.edu/dataset/34/diabetes', 'https://archive.ics.uci.edu/dataset/602/dry+bean+dataset', 'https://archive.ics.uci.edu/dataset/19/car+evaluation', 'https://archive.ics.uci.edu/dataset/545/rice+cammeo+and+osmancik', 'https://archive.ics.uci.edu/dataset/73/mushroom']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# fetch urls of all datasets\n",
    "\n",
    "list_url = []\n",
    "\n",
    "url = driver.find_elements(By.XPATH, '//a[@class=\"link-hover link text-xl font-semibold\"]') \n",
    "for i in url:\n",
    "    list_url.append(i.get_attribute(\"href\"))\n",
    "\n",
    "print(list_url)\n",
    "print(len(list_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "376c6569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Dataset Characteristics', 'Tabular'], ['Subject Area', 'Life Science'], ['Associated Tasks', 'Classification'], ['Feature Type', 'Real'], ['# Instances', '150'], ['# Features', '4'], ['Dataset Characteristics', 'Multivariate'], ['Subject Area', 'Life Science'], ['Associated Tasks', 'Classification'], ['Feature Type', 'Categorical, Integer, Real'], ['# Instances', '303'], ['# Features', '13'], ['Dataset Characteristics', 'Multivariate'], ['Subject Area', 'Social Science'], ['Associated Tasks', 'Classification'], ['Feature Type', 'Categorical, Integer'], ['# Instances', '48842'], ['# Features', '14'], ['Dataset Characteristics', 'Tabular'], ['Subject Area', 'Physical Science'], ['Associated Tasks', 'Classification'], ['Feature Type', 'Integer, Real'], ['# Instances', '178'], ['# Features', '13'], ['Dataset Characteristics', 'Multivariate'], ['Subject Area', 'Life Science'], ['Associated Tasks', 'Classification'], ['Feature Type', 'Real'], ['# Instances', '569'], ['# Features', '30'], ['Dataset Characteristics', 'Multivariate, Time-Series'], ['Subject Area', 'Life Science'], ['Associated Tasks', '-'], ['Feature Type', 'Categorical, Integer'], ['# Instances', '-'], ['# Features', '20'], ['Dataset Characteristics', 'Multivariate'], ['Subject Area', 'Computer Science'], ['Associated Tasks', 'Classification'], ['Feature Type', 'Integer, Real'], ['# Instances', '13611'], ['# Features', '16'], ['Dataset Characteristics', 'Multivariate'], ['Subject Area', 'Other'], ['Associated Tasks', 'Classification'], ['Feature Type', 'Categorical'], ['# Instances', '1728'], ['# Features', '6'], ['Dataset Characteristics', 'Multivariate'], ['Subject Area', 'Computer Science'], ['Associated Tasks', 'Classification'], ['Feature Type', 'Real'], ['# Instances', '3810'], ['# Features', '7'], ['Dataset Characteristics', 'Multivariate'], ['Subject Area', 'Life Science'], ['Associated Tasks', 'Classification'], ['Feature Type', 'Categorical'], ['# Instances', '8124'], ['# Features', '22']]\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "all_6 = []\n",
    "for i in list_url:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # scraping Attribute type\n",
    "    \n",
    "    all_6_elements = driver.find_elements(By.XPATH, \"//div[@class='col-span-4']\")\n",
    "\n",
    "    for i in all_6_elements:\n",
    "        all_6.append(i.text.split('\\n'))\n",
    "\n",
    "print(all_6)\n",
    "print(len(all_6))\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "73e0d63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tabular', 'Life Science', 'Classification', 'Real', '150', '4', 'Multivariate', 'Life Science', 'Classification', 'Categorical, Integer, Real', '303', '13', 'Multivariate', 'Social Science', 'Classification', 'Categorical, Integer', '48842', '14', 'Tabular', 'Physical Science', 'Classification', 'Integer, Real', '178', '13', 'Multivariate', 'Life Science', 'Classification', 'Real', '569', '30', 'Multivariate, Time-Series', 'Life Science', '-', 'Categorical, Integer', '-', '20', 'Multivariate', 'Computer Science', 'Classification', 'Integer, Real', '13611', '16', 'Multivariate', 'Other', 'Classification', 'Categorical', '1728', '6', 'Multivariate', 'Computer Science', 'Classification', 'Real', '3810', '7', 'Multivariate', 'Life Science', 'Classification', 'Categorical', '8124', '22']\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "general_1 = []\n",
    "\n",
    "for i in range(0, len(all_6)):\n",
    "    for j in all_6[i]:\n",
    "        if (len(all_6[i]) == 3):\n",
    "            all_6[i].pop(0)\n",
    "        general_1.append(j)\n",
    "                \n",
    "print(general_1)\n",
    "print(len(general_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3ee1b65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Real', 'Categorical, Integer, Real', 'Categorical, Integer', 'Integer, Real', 'Real', 'Categorical, Integer', 'Integer, Real', 'Categorical', 'Real', 'Categorical']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Scrape Attribute Type\n",
    "\n",
    "Attribute_Type = []\n",
    "\n",
    "for i in range(3, len(general_1), 6):\n",
    "    Attribute_Type.append(general_1[i])\n",
    "    \n",
    "print(Attribute_Type)\n",
    "print(len(Attribute_Type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f9974d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Donated on 6', '30', '1988'], ['Donated on 6', '30', '1988'], ['Donated on 4', '30', '1996'], ['Donated on 6', '30', '1991'], ['Donated on 10', '31', '1995'], ['Donated on 9', '13', '2020'], ['Donated on 5', '31', '1997'], ['Donated on 10', '5', '2019'], ['Donated on 4', '26', '1987']]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "Date = []\n",
    "for i in list_url:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # scraping Date\n",
    "      \n",
    "    Date_elements = driver.find_elements(By.XPATH, \"//h2[@class='text-sm text-primary-content']\")\n",
    "\n",
    "    for i in Date_elements:\n",
    "        Date.append(i.text.split('/'))\n",
    "            \n",
    "print(Date)\n",
    "print(len(Date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4bce664b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1988', '1988', '1996', '1991', '1995', '2020', '1997', '2019', '1987']\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Scrape Year\n",
    "year = []\n",
    "\n",
    "for i in range(0, len(Date)):\n",
    "    for j in Date[i]:\n",
    "        \n",
    "        if Date[i].index(j) == 2:\n",
    "            year.append(j)\n",
    "                \n",
    "print(year)\n",
    "print(len(year))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce82bc",
   "metadata": {},
   "source": [
    "## Q8 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "16451942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K</td>\n",
       "      <td>16</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1.73K</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset Name     Data Type            Task  \\\n",
       "0                                  Iris       Tabular  Classification   \n",
       "1                         Heart Disease  Multivariate  Classification   \n",
       "2                                 Adult  Multivariate  Classification   \n",
       "3                                  Wine       Tabular  Classification   \n",
       "4  Breast Cancer Wisconsin (Diagnostic)  Multivariate  Classification   \n",
       "5                              Diabetes             -               -   \n",
       "6                      Dry Bean Dataset  Multivariate  Classification   \n",
       "7                        Car Evaluation  Multivariate  Classification   \n",
       "\n",
       "               Attribute type No of Instances No of Attribute  Year  \n",
       "0                        Real             150               4  1988  \n",
       "1  Categorical, Integer, Real             303              13  1988  \n",
       "2        Categorical, Integer          48.84K              14  1996  \n",
       "3               Integer, Real             178              13  1991  \n",
       "4                        Real             569              30  1995  \n",
       "5        Categorical, Integer               -              20  2020  \n",
       "6               Integer, Real          13.61K              16  1997  \n",
       "7                 Categorical           1.73K               6  2019  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Dataset Name' : dataset_name[:8],\n",
    "    'Data Type':Data_Type[:8],\n",
    "    'Task':Task[:8],\n",
    "    'Attribute type':Attribute_Type[:8],\n",
    "    'No of Instances':No_of_instances[:8],\n",
    "    'No of Attribute':No_of_attribute[:8],\n",
    "    'Year':year[:8]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2b669f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466e1ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
